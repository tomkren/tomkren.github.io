\documentclass{sig-alternate}

\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage[ampersand]{easylist}
\usepackage{qtree}
\usepackage{color}


\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}



\newenvironment{lizt}
{\begin{easylist}[itemize]}
{\end{easylist}}

\newcommand{\Lets}{Let us\xspace}
\newcommand{\lets}{let us\xspace}
\newcommand{\lterm}{$\lambda$-term\xspace}
\newcommand{\lterms}{$\lambda$-terms\xspace}
\newcommand{\lhead}{$\lambda$-head\xspace}
\newcommand{\lheads}{$\lambda$-heads\xspace}
\newcommand{\la}{\leftarrow\xspace}
\newcommand{\Lp}  {\Lambda^{\prime}\xspace}
\newcommand{\tur}[3]{#1\vdash{}#2 \colon #3}
\newcommand{\turst}[3]{$#1\vdash{}#2:#3$\xspace}
\newcommand{\GMS}{\turst{\Gamma}{M}{\sigma}}
\newcommand{\atTree}{@-tree\xspace}
\newcommand{\setDots}[2]{ \lbrace #1 , \dots , #2 \rbrace}
\newcommand{\lh}[1]{\lambda #1}
\newcommand{\sexprTree}{sexpr-tree\xspace}
\newcommand{\SexprTree}{Sexpr-tree\xspace}
\newcommand{\then}{\Rightarrow\xspace}
\newcommand{\lamb}[2]{( \lambda \, #1 \, . \, #2 )}
\newcommand{\lam}[2]{\lambda \, #1 \, . \, #2}
\newcommand{\ST}{\mathop{\mathrm{ST}}}
\newcommand{\FV}{\mathop{\mathrm{FV}}}
\newcommand{\Scomb }{\mathbf{S}}
\newcommand{\Kcomb }{\mathbf{K}}
\newcommand{\Icomb }{\mathbf{I}}
\newcommand{\bbarr}{\twoheadrightarrow_\beta}
\newcommand{\barr}{\rightarrow_\beta}
\newcommand{\beq}{=_\beta}
\newcommand{\eearr}{\twoheadrightarrow_\eta}
\newcommand{\earr}{\rightarrow_\eta}
\newcommand{\eeq}{=_\eta}
\newcommand{\bearr}{\rightarrow_{\beta\eta}}
\newcommand{\bbeearr}{\twoheadrightarrow_{\beta\eta}}
\newcommand{\beeq}{=_{\beta\eta}}
\newcommand{\etar}{\twoheadrightarrow_\eta}
\newcommand{\ered}{$\eta$-reduction\xspace}
\newcommand{\bnf}{$\beta$-\textit{nf}\xspace}
\newcommand{\enf}{$\eta$-\textit{nf}\xspace}
\newcommand{\eenf}{$\eta^{-1}$-\textit{nf}\xspace}
\newcommand{\beenf}{$\beta\eta^{-1}$-\textit{nf}\xspace}
\newcommand{\benf}{$\beta\eta$-\textit{nf}\xspace}
\newcommand{\bredex}{$\beta$-redex\xspace} 
\newcommand{\lnf}{\textit{lnf}\xspace}
\newcommand{\Ae}{\mathop{\mathrm{\AE}}}
\newcommand{\Bcomb }{\mathbf{B}}   
\newcommand{\BBcomb }{\mathbf{B*}}
\newcommand{\Ccomb }{\mathbf{C}}   
\newcommand{\CCcomb }{\mathbf{C'}}
\newcommand{\SScomb }{\mathbf{S'}}
\newcommand{\ar}{\rightarrow\xspace}
\newcommand{\T}{\mathbb{T}\xspace}
\newcommand{\C}{\mathbb{C}\xspace}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\gar}{\longmapsto}

\newenvironment{todo}
{~\\ {\color{red}\textbf{TODO}}
  \begin{easylist}[itemize]}
{ \end{easylist}}

\newcommand{\Lpr}{\Lambda^\prime}
\newcommand{\ul}[2]{\langle #1 ; #2 \rangle}
\newcommand{\ro}[1]{{\color{blue} #1}}
\newcommand{\tom}[1]{{\color{ForestGreen} #1}}
\newcommand{\red}[1]{{\color{red} #1}}
\newcommand{\nehodi}[1]{{\color{yellow} #1}}



\begin{document}

\conferenceinfo{GECCO'14,} {July 12-16, 2014, Vancouver, BC, Canada.}
\CopyrightYear{2014}
\crdata{TBA}
\clubpenalty=10000
\widowpenalty = 10000

\title{Utilization of Reductions and Abstraction Elimination in Typed Genetic Programming}

\numberofauthors{2} 

\author{
% 1st. author
\alignauthor
Tom\'{a}\v{s} K\v{r}en\\
  \affaddr{Faculty of Mathematics and Physics}\\
  \affaddr{Charles University in Prague}\\
  \affaddr{Malostransk\'e n\'am\v{e}st\'\i~25, 11000,}\\
  \affaddr{Prague, Czech Republic}\\
  \email{tomkren@gmail.com}
% 2nd. author
\alignauthor
Roman Neruda\\
  \affaddr{Institute of Computer Science}\\
  \affaddr{Academy of Sciences of the Czech Republic}\\
  \affaddr{Pod Vod\'arenskou v\v{e}\v{z}\'\i~2, 18207,}\\
  \affaddr{Prague, Czech Republic}\\
  \email{roman@cs.cas.cz}
}

%\date{24 January 2014}

\maketitle
\begin{abstract}
Lambda calculus representation of programs offers a more expressive alternative to traditional S-expressions. In this paper we discuss advantages of this representation coming from use of reductions (beta and eta) and how to overcome disadvantages caused by variables occurring in the programs by use of the abstraction elimination algorithm. We discuss the role of those reductions in the process of generating initial population and compare several crossover approaches including novel approach to crossover operator based both on reductions and abstraction elimination. The design goal of this operator is to turn the disadvantage of abstraction elimination  - possibly quadratic increase of program size - into a virtue; our approach leads to more crossover points. At the same time, utilization of reductions provides offspring of small sizes.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{TODO}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{TODO}

\keywords{TODO, ToDo, todo}

\section{Introduction}


Genetic programming (GP) represents an efficient method for automatic generating of programs by means of evolutionary techniques~\cite{koza92,koza03}. Early attempts to enhance the GP approach with the concept of types include the seminal work~\cite{montana95} where the ideas from Ada programming language were used to define a so-called strongly typed GP.   
Use of types naturally opens door to enriching S-expressions,
the traditional GP representation of individuals, with concepts from
lambda calculus, which is simple yet powerful functional, mathematical and programming language extensively used in type theory. Such attempts has shown to be successful \cite{yu01}. 

%Other ...
\red{ 

Todele asi šoupnout do related work.

%Reprezentace v klasickym kozovy je S-expression.

The individual representation used in standard GP is S-expression. 
Basically there are two general approaches of generalizing S-expressions
into trees of better expressive power suitable for typed GP with higher 
order functions: We can enrich the method with the polymorphic combinators \cite{kes}
or we can enrich the method with the lambda abstractions and local variables
\cite{yu01}.  

Pokud chceme dělat GP nad stromama větší vyjadřovací síly než maj klasický S-výrazy, tak máme v záse dvě přirozený možnosti pro obecný řešení: buď to dělat celý v (polymorfních) kombinátorech od začátku (a vyhnout se tak proměnejm a lambda abstrakcím), nebo to skusit v lambda kalkulu a nejak se vypořádat s proměnejma a lambdama. 

Zdá se že použití kombinátorů má řadu výhod (vymenovat nějaký co jmenuje briggs), 
ale konzistentní prozkoumání obecnýho řešení lambdovýho charakteru určitě stojí 
taky za zkoužku, což podporují nasledující argumenty:

  (a) motivace pro práci s lambda termama je, že za nima košatá teorie, 
      která například popisuje redukce lambda termů (ty zajišťujou jak 
      zmenšení samotných stromu, tak to, že prohledávací prostor se zmenší, 
      díky tomu, že se různé stromy redukují na ten samej).
      (ALT znění: 
      pohovořit o tom, že normální formy zmenšujou prohledávaný prostor, 
      protže stačí brát v potaz třídy ekvivalence a ne zamotný termy 
      - reprezentanti těchto tříd ekvivalence jsou pak právě normální formy. )
      (ALT2: 
      Dost podstatný ospravedlnění lambda reprezentace je fakt, 
      že redukce (beta, eta) šlapou právě jen při tom, když máme lambdy.)

  (b) úspornost - abstrakce eliminací produkuje 
      termy až kvadraticky větší než je původní 
      term. Dá se očekávat, že i při přímém generování je použití kombinátorů 
      míň úsporný (proměná se může bez velký námahy objevit v hluboko vnořeném
      podtermu velmi jednoduše, zatímco pomocí kombinátorů se její hodnota musí do
      takto vnořeného podtermu složitě dopravit). 

  (c) použití kombů vyžaduje silnější typovej sytém - 
      kombinátory musej bejt polymorfní a přidáváme je do stavební sady,
      lambdy v pohodě běžej na simply typed lc. 

  (d) použití proměnných je typické pro lidi, proto by se mohlo sát že
      i programy generovaný systémem kterej s proměnejma počitá budou o něco 
      "lidštější"



Since abstr-elim a redukce neinvolvujou moc typově rilejtlý problémy, je ok celou věc demostrovat na jednoduchém typovém systému jakám je simply typed lc. Pro more soffisticated type systems would be situation similar.

Hlavním problémem lambda reprezentac proti kombinátorový je 
jak se vypořádat s problémy zpusobenými použitím 
localních proměných (aka jak křížit).

}

%\nehodi{The key issue in the lambda calculus approach to enrich GP with types is the method of individual generation. During the expansion phase the set of unfinished terms can be browsed with respect to various search strategies. Our approach to this problem aims to utilize the full arsenal given by the simply typed lambda calculus. Thus, the natural idea is to employ an exhaustive systematic search. On the other hand, if we were to mimic the standard GP approach, a quite arbitrary yet common and successful ramped half-and-half generating heuristic~\cite{fg} should probably be used. These two search methods in fact represent boundaries between which we will try to position our parameterized solution that allows us to take advantage of both strategies. This design goal also differentiate our approach from the three state of the art proposals for typed GP known to us that are discussed in the following section. Our proposed \emph{geometrical search strategy} described in this paper is such a successful hybrid mixture of random and systematic exhaustive search. Experiments show that it is also very efficient dealing with one of the traditional GP scarecrows - the bloat problem.}

\red{ve shrnutí paperu říct, že jeho tělo je tvořeno dvěma částma,
první se zabejvá generovánim a jeho vztahem k redukcím, druhá řeší křížení
s velkym důrazem na vyřešení problémů s lokálníma proměnejma.}

The rest of the paper is organized as follows: The next section briefly discusses related work in the field of typed GP, while section~\ref{preliminaries} introduces necessary notions. Main original results about search strategies in individual generating are described in section~\ref{approach}. Section~\ref{experiments} presents results of our method on three well-known tasks, and the paper is concluded by section~\ref{conclusions}.

\subsection{\red{Randombits}}
\red{

- někam poznamenat že přínos toho článku je taky v tom že zpřístupňuje pojmy z teorie typovaného lc komunitě typovaného GP.. 


}



\section{Related work}
\label{related}

\red{TODO zatim jen zkopčený z minula, opravit podle novýho kontextu,
možná přesunout velkou obhajobu z úvodu sem..}

Yu presents a GP system utilizing
polymorphic higher-order functions\footnote{Higher-order 
function is a function taking another function as 
input parameter.} and lambda abstractions  \cite{yu01}.
Important point of interest in this work is use of
\texttt{foldr} function as a tool for \textit{implicit recursion},
i.e. recursion without explicit recursive calls. 
The terminal set for constructing lambda abstraction subtrees 
is limited to use only constants and variables of that particular
lambda abstraction, i.e., outer variables are not allowed to be used
as terminals in this work. This is significant difference from our approach 
since we permit all well-typed normalized \lterms. From this difference also
comes different crossover operation. We focus more on term generating process; 
their term generation is performed in a similar way as the standard one, 
whereas our term generation also tries to utilize techniques of systematic enumeration. 

Briggs and O’Neill present technique 
utilizing typed GP with combinators \cite{kes}.
The difference between approach presented in this work
and our approach is that in this work terms are generated
straight from \textit{library} of combinators and no lambda abstractions
are used. They are using more general polymorphic type system than us
-- the Hindley–Milner type system. They also discuss the 
properties of exhaustive enumeration of terms and compare it with GP search.  
They also present interesting concept of \textit{Generalized
genetic operator} based on term generation. 

Binard and Felty use even 
stronger type system (\textit{System F}) \cite{binard2008genetic}.  
But with increasing power of the type system comes increasing difficulty of term generation.
For this reason evolution in this work takes interesting and nonstandard shape 
(fitness is associated with \textit{genes} which are evolved together with \textit{species}
which together participate in creation of individuals).
This differs from our approach, which tries to be generalization of
the standard GP\cite{koza92}.

In contrast with above mentioned works our approach uses very simple type system 
(simply typed lambda calculus) and concentrates on process of generation  
able to generate all possible well-typed normalized lambda terms. In order to do
so we use technique based on \textit{inhabitation machines} 
described by Barendregt \cite{barendregt10}.    



\section{Preliminaries}
\label{preliminaries}

In this section, several notions necessary to build a typed GP based on lambda calculus are introduced. 
First, \lets describe a programming language, 
in which the GP algorithm generates individual programs --- the so called \lterms.

\begin{definition}
Let $V$ be infinite countable set of {\it 
variable names}. Let $C$ be set of {\it constant names}, 
$V \cap C = \emptyset$.	 	
Then $\Lambda$ is set of {\it \lterms} defined inductively as follows.	
\begin{align*}
x   \in V \cup C  &\then x     \in \Lambda \\
M,N \in \Lambda   &\then (M~N) \in \Lambda 
\textit{~~~~~~(Function application)} \\
x   \in V , M \in \Lambda &\then \lamb{x}{M} \in \Lambda
\textit{~~~~($\lambda$-abstraction)} 
\end{align*}
\end{definition}


\textit{Function application} and 
\textit{$\lambda$-abstraction} are concepts
well known from common programming languages. 
For example in JavaScript 
$(M~N)$ translates to expression \texttt{$M$($N$)} and
$\lamb{x}{M}$ translates to expression \texttt{function($x$)\{return $M$;\}}.
In other words, the function application 
corresponds to the act of supplying a function 
with an argument, and
the $\lambda$-abstraction is equivalent to 
\textit{anonymous function}\footnote{Apart from JavaScript, anonymous functions are common e.g. in Python and Ruby, 
they were recently introduced to C++, and they are expected to be supported in Java 8.}.

For better readability, 
$M_1~M_2~M_3~\dots~M_n$ is an abbreviation for
$(\dots((M_1~M_2)~M_3)~\dots~M_n)$
and $\lam{x_1 x_2 \dots x_n }{M}$ for 
$\lamb{x_1}{\lamb{x_2}{\dots\lamb{x_n}{M}\dots}}$.


\subsection{$\beta$-reduction}

In order to perform computation there must be some
mechanism for term evaluation. In $\lambda$-calculus there
is $\beta$-reduction for this reason.\\

\newcommand{\bRedex}{$\beta$-redex\xspace}
\newcommand{\bRedexes}{$\beta$-redexes\xspace}
\newcommand{\bArrow}{\rightarrow_\beta\xspace}
\newcommand{\eArrow}{\rightarrow_\eta\xspace}
\newcommand{\eeArrow}{\rightarrow_{\eta^{-1}}\xspace}

A term of a form $\lamb{x}{M}N$ is called \textit{\bRedex}.
A \bRedex can be $\beta$-reduced to term $M[x:=N]$. 
This fact is written as \textit{relation} $\bArrow$ 
of those two terms:
\begin{equation} \label{eq:bRed}
\lamb{x}{M}N \bArrow M[x:=N]
\end{equation}
It is also possible to reduce \textit{subterm \bRedexes} 
which can be formally stated as:
\begin{align*}
P \bArrow Q &\then (R~P)      \bArrow (R~Q) \\
P \bArrow Q &\then (P~R)      \bArrow (Q~R) \\
P \bArrow Q &\then \lam{x}{P} \bArrow \lam{x}{Q}  
\end{align*}

In other words, $\beta$-reduction is the process 
of insertion of arguments supplied to a function into 
its body. \\

Another useful relations are $\bbarr$ and $\beq$ defined as follows. 

\begin{enumerate}
 \item \begin{enumerate}
 	\item $M \bbarr M$
 	\item $M \barr N \then M \bbarr N$
 	\item $M \bbarr N , N \bbarr L \then M \bbarr L$ 	
 \end{enumerate}
 \item \begin{enumerate}
 	\item $M \bbarr N \then M \beq N$
 	\item $M \beq N \then N \beq M$
 	\item $M \beq N , N \beq L \then M \beq L$
 \end{enumerate}

\end{enumerate}

We read those relations as follows.
\begin{enumerate}
 	\item $M \bbarr N$ --- "$M$ $\beta$-reduces to $N$."  
 	\item $M \barr N$  --- "$M$ $\beta$-reduces to $N$
 	      in one step."
 	\item $M \beq N$ --- "$M$ is $\beta$-convertible to $N$."	
 \end{enumerate}



\subsection{$\eta$-reduction}

Similarly as for $\beta$-reduction we can define $\eta$-reduction 
except that instead of \ref{eq:bRed} we use:  

$$\lamb{x}{(M~x)} \eArrow M \textbf{ ~~~~if } x \not\in FV(M) $$~

Analogically, a term of a form $\lamb{x}{(M~x)}$ is called 
\textit{$\eta$-redex}.

Relation $\bearr\;=\;\barr \cup \earr$. 
(Relation $R = \{\;(a,b)\;|\;a\;R\;b\;\}$.)

Similarly as for $\bbarr$ and $\beq$ we can define relations 
$\eearr$, $\eeq$,$\bbeearr$ and $\beeq$.


\subsection{$\eta^{-1}$-reduction}

$\eta^{-1}$-reduction (also called $\eta$-expansion) is 
the reduction converse to $\eta$-reduction.
Again it may be obtained by replacing \ref{eq:bRed}, now with:  

$$M \eeArrow \lamb{x}{(M~x)} \textbf{ ~~~~if } x \not\in FV(M) $$




\subsection{Normal forms}

~\begin{easylist}[enumerate]
& A \lterm is a \textit{$\beta$-normal form} (\bnf) 
if it does not have a $\beta$-redex as subterm.
& A \lterm M \textit{has} a \bnf if $M \beq N$
and $N$ is a \bnf.\\
\end{easylist}
A normal form may be thought of as a result of a term evaluation. 

Similarly we can define \enf and \benf.



\subsection{Types etc}

A \lterm as described above
corresponds to a program expression with no type information
included. Now we will describe \textit{types} (or \textit{type terms}).

\begin{definition}
Let $A$ be set of {\it atomic type names}. 
Then $\mathbb{T}$ is set of {\it types} inductively defined as follows.
\begin{align*}
\alpha      \in A  &\then   \alpha \in \T \\
\sigma,\tau \in \T &\then ( \sigma \ar  \tau ) \in \T 
\end{align*}
\end{definition}


Type $\sigma \ar \tau$ is type for functions taking as input
something of a type $\sigma$ and returning 
as output something of a type $\tau$. 
$\tau_1 \ar \tau_2 \ar \dots \ar \tau_n$ is an abbreviation for 
$\tau_1 \ar (\tau_2 \ar (\dots \ar (\tau_{n-1} \ar \tau_n)\dots))$.
The system called \textit{simply typed $\lambda$-calculus} is now easily obtained by
combining the previously defined \textit{\lterms} and \textit{types} together.

\begin{definition}~

\begin{enumerate}
 \item 	Let $\Lambda$ be set of {\it \lterms}. 
	Let $\mathbb{T}$ be set of {\it types}.       
	A {\it statement} $M : \sigma$ is a pair 
	$(M,\sigma) \in \Lambda \times \mathbb{T}$.
	Statement $M : \sigma$ is vocalized as 
	{\it "$M$ has type $\sigma$"}.
	The term $M$ is called the {\it subject} of the 
	statement $M : \sigma$.
 \item A \textit{declaration} is a statement 
 $x : \sigma$ where $x \in V \cup C$.
  
 \item A \textit{context} 
 is set of declarations with distinct variables as subjects.
\end{enumerate}
\end{definition}
%~\\

Context is a basic type theoretic concept suitable as a typed alternative
for terminal and function set in standard GP. 
Notation $\Gamma,x:\sigma $ denotes $ \Gamma\cup\{(x:\sigma)\}$ 
such that $\Gamma$ does not contain any declaration with $x$ as subject.
We also write $x:\sigma \in \Gamma$ instead of $(x,\sigma) \in \Gamma$.

\begin{definition}
A statement $M\colon\sigma$ is \textit{derivable from}
a context $\Gamma$ (notation 
\mbox{$\Gamma\vdash{}M\colon\sigma$}) 
if it can be produced by the following rules.
\begin{align*}
x : \sigma \in \Gamma &~\then~ \tur{\Gamma}{x}{\sigma}\\
\tur{\Gamma}{M}{\sigma \ar \tau}~,~\tur{\Gamma}{N}{\sigma} 
&~\then~ \tur{\Gamma}{(M~N)}{\tau}\\  
\tur{\Gamma,x:\sigma}{M}{\tau}
&~\then~ \tur{\Gamma}{\lamb{x}{M}}{\sigma \ar \tau} 
\end{align*}
\end{definition}

Přeformulovat aby se to hodilo do tohodle kontextu....
Our goal in term generation is to produce terms $M$
for a given pair $\ul{\tau}{\Gamma}$
such that for each $M$ is $\tur{\Gamma}{M}{\tau}$.


\subsection{Long normal form}
\label{lnf}

%v barendrechtovi je to v definici lnf
%$\lam{x_1 \dots x_n}{f~M_1~\dots~M_n}$ místo $M_m$ 
%ale to musí bejt určitě překlep...

\begin{definition}
Let \GMS where 
$\sigma = \tau_1 \ar \dots \ar \tau_n \ar \alpha, n \geq 0$.
	\begin{enumerate}
	  \item	
		Then $M$ is in \textit{long normal form} (\lnf) if following 
		conditions are satisfied.
		\begin{enumerate}
		 \item $M$ is term of the form $\lam{x_1 \dots x_n}{f~M_1~\dots~M_m}$\\
		  (specially for $n = 0$, $M$ is term of the form $f$).
		 \item Each $M_i$ is in \lnf.
		\end{enumerate}	
	  \item 
	    $M$ has a \lnf if $M =_{\beta\eta} N$ and $N$ is in \lnf.
	\end{enumerate}
\end{definition}~

As is shown in \cite{barendregt10}, \lnf has following nice properties.

\begin{proposition}
If $M$ has a \bnf, 
%which according to Theorem 2B.4 is always the case, 
then it also has a unique \lnf, 
which is also its unique \beenf.
\end{proposition}

\begin{proposition}
Every $B$ in \bnf has a \lnf 
$L$ such that $L \twoheadrightarrow_{\eta} B$.
\end{proposition}

\subsection{Abstraction elimination}

\textit{Abstraction elimination} is a process of transforming 
an arbitrary \lterm into \lterm that contains no lambda abstractions
and no bound variables.
The newly produced \lterm may contain function applications, 
free symbols from former \lterm and some new symbols standing for 
combinators $\Scomb$, $\Kcomb$ and $\Icomb$. \\

Those combinators are defined as:
\begin{align*}
\Scomb &= \lam{f\,g\,x}{f\,x\,(g\,x)} \\
\Kcomb &= \lam{x\,y}{x} \\
\Icomb &= \lam{x}{x} 
\end{align*}


\Lets describe transformation $\Ae$ performing this 
process.
%\footnote{In our implementation we must also deal with types, because our individuals are annotated with types. But since this process is fairly straightforward but cumbersome to describe, we will skip explaining it here. Reader interested in seeing it can see the source code of our implementation. }
\begin{align*}
\Ae[x]           &= x &\\[0.4em]
\Ae[\,(M\,N)\,]  &= (\Ae[M]\;\;\Ae[N]) &\\[0.4em]
\Ae[\lam{x}{x}]  &= \Icomb &\\
\Ae[\lam{x}{M}]  &= (\Kcomb~\Ae[M]) &\textbf{if } x \not\in \FV(M)\\
\Ae[\lam{x}{\lamb{y}{M}}] &= \Ae[\lam{x}{\Ae[\lam{y}{M}]}]  
&\textbf{if } x \in \FV(M)\\
\Ae[\lam{x}{(M\,N)}] &= (\Scomb~\Ae[\lam{x}{M}]~\Ae[\lam{x}{N}])  
&\textbf{if } x \in \FV(M)\\
&&\vee~ x \in \FV(N)\\
\end{align*}


This is simple version of this process. More optimized version,
in the means of the size of resulting term and its performance
is following one, presented in \cite{jones87}.\\


As is stated in \cite{jones87},
the biggest disadvantage of this technique is that the translated
term is often much larger than in its lambda form --- the size of
the translated term can be proportional to the
square of the size of the original term. 

But the advantage is also tempting --- no need to deal with variables
and lambda heads.

\red{tady je to v původnim kontextu, odebrat slova co se tam nehodí}

\section{Term generating and reductions}

This section is focused on the individual generating method producing
terms in their long normal form, which can be understood as a straight 
generalization of S-expressions into lambda calculus. 
We discuss the relation between terms in \lnf with beta and eta reductions,
the advantages of such representation and we also show how to easily 
transform such terms into short \benf.
   
\subsection{Grammar producing \lterms in \lnf}

In \cite{barendregt10} is shown term generating grammar with 
following rules.

\red{předělat ten zápis, víc to okecat, říct že to je jakoby gramatika, 
formálně 2-level-gramatika do footnoty, pač má nekonečně neterminálu  
i terminálů. že neterminaly jsou dvojice (typ, kontext) a že terminaly jsou
symboly kterejma se zapisujou lambda termy}

\begin{align*}
( \alpha , \Gamma )  
&\gar
(~f~( \rho_1 , \Gamma )~\dots~( \rho_m , \Gamma )~)
\\& \textbf{if } \alpha \in A,
(f : \rho_1 \ar \dots \ar \rho_m \ar \alpha) \in \Gamma
\\ 
( \sigma \rightarrow \tau , \Gamma )  
&\gar
(~\lambda~x~.~( \tau ; \Gamma,x:\sigma )~)
&   
\end{align*}

The second rule can be replaced by more effective one.
$ 
( \tau_1 \ar \dots \ar \tau_n \ar \alpha , \Gamma )  
\gar \\
(~\lambda~x_1~\dots~x_n~.~
( \alpha ; \Gamma , x_1:\tau_1 , \dots , x_n:\tau_n  )~)
~~~~ \textbf{if } n > 0
$ 

This rule packs consecutive uses of the second rule into one use.
This is valid since the use of the second rule is deterministic;
it is used if and only if the non-terminal's type is not atomic.

Long normal form is a generalization of S-expressions into lambda calculus:
Let $\Gamma$ be a context satisfying the closure requirement, then only
the first rule will be applicable. 
$(\alpha, \Gamma)$ rewrites to $(~f~( \alpha, \Gamma )~\dots~( \alpha, \Gamma )~)$.
One can see that $f$ stands for 
the root node and that each $( \rho_i , \Gamma )$ will produce a direct subtree. 

\red{
For context containing at least one higher order function we get special kind of root node containing lambda head with one direct subtree standing for body of 
the lambda function, v tomto tele se navíc mohou objevit proměnné 
definované v této hlavě (asi doplnit obrázkama).

Diskuze toho jakou přesnou strategií je nejvhodnější generovat
termy v lnf je beyond the scope of this paper, mužeme například použít
klasickou raped half-and half strategii. Footnotenout kraťoučkou
zmínku o gemetrický. 
}


\subsection{Benefits of generating \lterms in \lnf}
\label{benefits}

By generating \lterms in \textit{lnf} we avoid generating 
\lterms $M$,$N$ such that $M \not= N$, but $M =_{\beta\eta} N$.
In other words, we avoid generating two programs with different 
source codes, but performing the same computation.

Every \lterm $M$ such that \GMS has its unique \lnf $L$, 
for which $L =_{\beta\eta} M$.
Therefore the computation performed by \lterm $M$ 
is not omitted, because it is the same computation
as the computation performed by \lterm $L$. \\

Generating \lterms in \lnf is even better than generating 
\lterms in \bnf. Since \lnf is the same thing as \beenf,
every \lterm in \lnf is also in \bnf. 

This comes straight from the definition of \beenf, 
but one can also see it from observing method for generating
terms in \bnf. As is shown in \cite{barendregt10}, 
this method is obtained simply by replacing  
the first grammar rule by slightly modified rule,
resulting in the following grammar.
\begin{align*}
( \pi , \Gamma )  
&\gar
(~f~( \rho_1 , \Gamma )~\dots~( \rho_m , \Gamma )~)
\\& \textbf{if } (f : \rho_1 \ar \dots \ar \rho_m \ar \pi) \in \Gamma
\\ 
( \sigma \rightarrow \tau , \Gamma )  
&\gar
(~\lambda~x~.~( \tau ; \Gamma,x:\sigma )~)
&   
\end{align*}

The difference lies in that $f$'s type is no longer needed to be fully expanded
($\pi \in \T$ instead of $\alpha \in A$). This makes the grammar less deterministic,
resulting in a bigger search space. The new rule is generalization of the old one,
thus all terms in \lnf will be generated, along with many new terms in \bnf that 
are not in \lnf. 
    
By generating \lterms in \lnf we avoid generating 
\lterms $M$,$N$ such that $M \not= N$ and $M =_{\eta} N$; 
but by generating in \bnf we do not avoid it.\\


The disadvantage of the \lnf, as the name suggests, is that it is long.
Terms in \lnf are said to be \textit{fully $\eta$-expanded} \cite{barendregt10}. 
Relevant property of $\eta$-reduction is that it always shortens the term
that is being reduced be it. And conversely, $\eta$-expansion prolongs.
$$\lamb{x}{(M~x)} \eArrow M \textbf{ ~~~~if } x \not\in FV(M) $$

Now we show that for every \lterm $M$ 
every sequence of $\eta$-reductions is finite and
leads to unique \enf $N$.

\begin{enumerate}
 \item Every application of \ered shortens the term.
       Since every term has finite size, this process must 
       end at some point. Thus every \lterm has \enf.
 \item Since \ered is \textit{Church–Rosser}, \enf is unique (see \cite{barendregt84}). 
\end{enumerate}

So we can take every generated \lterm $M$ in 
\lnf and transform it to shorter term in \enf. 
The question is whether it remains in \bnf, thus being in \benf.
The answer is yes; it can be proven by showing that no 
new \bredex is created by \ered.  

\begin{proposition}
Let $P$ be in \bnf and $P \eArrow Q$. Then $Q$ is in \bnf.    
\end{proposition}
\begin{proof}

For better clarity \lets show the \ered and \bredex using trees.\\
\ered: \\

\Tree [.$\lh{x}$ [.@ $M$ $x$ ] ] 
~~~~$\eArrow$~~~~
$M$ 

And \bredex:

\Tree [.@ [.$\lh{x}$ $M$ ] $N$ ] \\

\Lets assume that $P \eArrow Q$ creates a new \bredex $B$ in $Q$.

Since \ered only destroys and never creates \textit{function applications} (i.e. @),
the root @ of $B$ must be present in $P$.  
But since $P$ contains no \bredex, the left subterm $L$ of this root @
is not $\lambda$-abstraction.
Only possible way for $L$ to be changed by $\eArrow$ into 
a $\lambda$-abstraction is that $L$ is the reduced subterm (so that
$L$ is changed for its subterm).
But that is in contradiction with $P$ not containing any \bredex,
because it would cause $L$ be a $\lambda$-abstraction.
\end{proof}

Notable property of \lnf and \benf is that there is \textit{bijection} 
(i.e. one-to-one correspondence) of 
the set of simply typed \lterms in \lnf and 
the set of simply typed \lterms in \benf.

\begin{proposition}

Reduction to \enf is bijection between  
the set of simply typed \lterms in \lnf and 
the set of simply typed \lterms in \benf.
\end{proposition}
\begin{proof}

Since reduction to \enf always leads to an unique term, it is a function.
In previous proposition is shown that \ered of \lnf
leads to a term in \benf.\\

In order to show that a function is bijection it is sufficient to show that it is
both \textit{injection} and \textit{surjection}.\\

Suppose it is not injection.

So there must be $M_1,M_2$ in \lnf such that $M_1 \not= M_2$
and $N$ in \benf such that $M_1 \etar N$, $M_2 \etar N$.
Therefore $M_1 =_\eta M_2$, 
so $M_1 =_{\beta\eta^{-1}} M_2$.
This contradicts with $M_1,M_2$ being distinct \lnf{}s.\\

Every $M$ in \bnf has a \lnf $N$ such that 
$N \twoheadrightarrow_{\eta} M$ (proposition from \ref{lnf}).
Term $M$ in \benf is in \bnf, thus it has desired \lnf $N$
which reduces to it. 

Therefore it is surjection. 
\end{proof}

Suppose we have systematic (i.e. gradually generating all terms, 
but no term twice) method for generating terms in \lnf,
we may transform it to systematic method for generating terms in \benf
by simply reducing each generated term to its \enf.  


\section{Crossover operator}


The design goal behind our approach to the crossover operation is
to try to generalize the standard tree swapping crossover.


The crossover operation in standard GP is performed 
by swapping randomly selected subtrees in each parent 
S-expression.
For typed lambda terms two difficulties arise: Types and variables.

As in standard GP our crossover will be performed by swapping
two subtrees. But now with constraint that both subtrees have
the same type. 

Variables bring more difficulties then types do.
This problem arises from variables that are free in subterms corresponding 
to swapped subtrees. 

Following example illustrates the problem. \Lets have these two
parent trees with selected nodes in bold.\\

\Tree [.$\lh{x_1}$ [.f [.$\lh{x_2}$ [.\textbf{g} $x_2$ c ] ] $x_1$ ] ]
\Tree [.$\lh{x_1}$ [.h $x_1$ $\mathbf{x_1}$ ] ]

~\\The swap of subtrees results in following trees:\\

\Tree [.$\lh{x_1}$ [.f [.$\lh{x_2}$ $\mathbf{x_1}$ ] $x_1$ ] ]
\Tree [.$\lh{x_1}$ [.h $x_1$ [.\textbf{g} $\mathbf{x_2}$ \textbf{c} ] ] ]
 
~\\The problem is that variable $x_2$ in second tree
is not bound by any $\lambda$-head and since
it is not element of $\Gamma$, the second tree is not well-typed \lterm.  

Generally speaking, the variable problem is caused by that the local variable is not defined in the new place or the variable is defined in the new place, but has
some another type.

Let us list some possible approaches to solving this problem:

%Už přeloženo: 
%Hlavní problém: proměnné - pokud se odtržený podterm obsahuje volnou proměnnou, taková proměná může ve svém novém umístění porušit well typednost vzniklého termu - ať už z důvodu toho že tam není vubec definována, nebo tam sice je, ale má jiný typ.  
%Metody jak zacházet s lambdama:
%- použít méně obecnou reprezentaci, takovym příkladem je Yu, která nepovoluje vnější proměný uvnitř lambda abstrakcí a další restrikce. Touto cestou nechceme jít, myslime si že stojí za to udělat takovou reprezentaci, která nepřeskočí normální formu žádného well-typed termu.
%- křížit tak jako by se nic nedělo a problémy řešit až když nastanou: tzn buď přejmenovat promenou na takovou, která v daném kontextu má správný typ nebo ji nahradit, případně ji nahradit nově vygenerovaným termem požadovaného typu. Takový přístup se nam taky nelíbí, dá se očekávat že takové kolize budou častý, při nemožnosti vhodně přejmenovat proměnnou navíc do křížení přibívá prvek mutace. K takovému řešení se zdá dobé přistoupit až ve chvíli, kdy nezbejvá jiná čistčí možnost.
%Pro vyřešení problémů s proměnými se dá použít elegantní řešení: zbavit se proměných. Toho jde docílit použitím algoritmu eliminace abstrakcí, který převede term na ekvivalentní term který neobsahuje žádné proměné a lamb abstrakce, zato obsahuje navíc kombinátory (v nejjdednoduší verzi S,K a I), které zastanou puvodní roli proměnných. We idetified two methods using this approach:

One option is to choose a less general representation of lambda terms.
Such approach is successfully used in \cite{yu01} where the 
terminal set for constructing lambda abstraction subtrees 
is limited to use only constants and variables of that particular
lambda abstraction and an appropriate variable naming convention is
used in order to prevent troubles with variables.
We choose not to follow such approach because we do not want to
lose the opportunity to represent every possible well-typed 
term in its normal form.

Another option is to overlook the variable problems and to correct the
defects when they occur. Such correction can be performed by 
renaming the problematic variable to some another variable defined in that place 
or, if there is no suitable candidate, to replace its occurrence with 
a newly generated term of required type. This approach seems to us as a very
unwieldy one -- there are clearly problems for which such collisions would
occur very often and when there is no suitable rename candidate the 
generation of new term brings the unnecessary element of a mutation.
Such solution seems to be useful only as a last resort.

There is an elegant way to overcome the problem with variables by getting rid of them.
This is possible thanks to the abstraction elimination algorithm described above.
It turns a \lterm into a \lterm that contains no lambda abstractions
and no variables, instead, it contains additional function symbols standing for 
polymorphic combinators (i.e. $\Scomb$, $\Kcomb$ and $\Icomb$ 
in the simple case of the algorithm). 

We identified two methods using this approach:

\red{


- Na konci generovací fáze všechny vygenerované termy převést do kombinatorové
  podoby pomocí elmin abstr. Tento přístup můžeme chápat jako kompromis (najit lepší slovo, hibrid...) mezi lambda reprezentací a komb reprezentací. Nastává však otázka zda má pak smysl generovat termy v lc, když je pak stejně převedeme. (Výhodou je, že
při generování v kombinátorech nemáme zajištěno že (pokud bychom nahradili S,K,I 
za odpovídající termy a redukovlaito,tak že nevygenerujeme dvakrát různej term co se redukuje do toho samýho - což je ale takova divná výhoda kerou bych asi ani nepsal nebo nevim) Převod má totiž až kvadratický nárůst velikosti a dá se očekávat, že termy jsou při přímém generování v komb metodě generovany usporněji (čili to co sme nahnali na redukcích stratíme eliminací).

- Jedince držet po celou dobu v be-nf (té nejúspornější co se týče 
  beta,eta-redukcí) a pouze při křížení oba rodiče převést na kombinátorovou formu
  eliminací abstrakcí. Po zkřížení je zase uvést do be-nf neobsahující přidané kombinátory tak, že jejich výskyty nahradíme jejich definicemi 
  (e.g. K nahradime termem (\ x y . x) ) a tento term redukujeme 
  do beta eta nf. Takový přístup využívá dříve nelibou vlastnost eliminace totiž kvadratický narust velikosti ku svému prospěchu, zde totiž k tomuto nárůstu dochází pouze dočasně a tím zvyšuje počet křížících bodů, což se ukazuje jako výhoda (citovat Yu kde při použití @-reprezentace místo s-výrazů dosahuje lepších výsledků). Díky redukcím jsou pak výsledné termy zase nejmenčí co v dáné "třídě ekvivalence" mohou být. Nevýhodou je, že takový operace žerou nějakej čas. Je však otázkou, do jaké míry je takový overhead (kouknout co toslovo znamena:D) podstatný, jelikož na druhou stranu 
  z keeping trees small přichází že to bude celý rychlejší a je otazka zda bude takový overhead podstatný v porovnání s overheadem pro výhodnocení termu, který je typicky nejdražší. Zvlášť přitažlivý mi tohle křížení příde i kvůli tomu, že v přírodě se taky rozbalujou a zabaloujou chromozomi při meioze/mitoze.
  
  
%(ALTernativní znění ze začátku: Jedince držíme jako redukovane malinké-kompaktní-a-elegantní lambda termy. Ve chvíly kdy křížíme provedeme na obou rodičích eliminaci abstrakcí (která ubere proměný a lambdy a namísto toho tam dá kombinátory S,K,I případně i další při fikanějších eliminacích), tím nám sice narostou, ale my z toho máme jedine radost, protože tím se nám zvýšil počet míst ke křížení (což se ukazuje jako dobráv věc, viz s-expr reprezentace vs @-tree reprezentace lambda termů). Po skřížení se vložený kombinátory nahradí odpovídajícim lambda termem (tzn např všude kde je K dám (\ x y . x) atd) výslednej term zredukuju a dostávam zase malinké-kompaktní-a-elegantní dítě.Nevýhoda toho zahrnout do článku i tohle je v tom, že k tomu nemám ještě žádný pokusy - ale k tomu zbytku mám upřímě v zato taky dost ubohý pokysy, takže toho bych se asi nebál. Většinu potřebnýho kodu bych k tomu ale měl už mít víceméně hotovou, takže pokud by se to na něčem nezaseklo, tak myslim že je realný udělat i pokus do toho dvacátýho.)

}

\subsection{Poznámky k uvodu ke křížení}
\red{
POZNAMKY:

CO S @-stromama řešit je explicitně tady, případně někde jinde? Pro generování nemá reprezentace vliv, ta má vliv až vpři křížení, kde at-tree zajišťuje víc míst. We will show how to crossover \textit{typed \lterm trees} in both \atTree and \sexprTree notation.

to o tom že chem zobecnit tu standardní furt platí, protože na s-výrazy se eta redukce ani abstr elim nevztahuje, někde to zmínit že se to na ně nevztahuje
}


\subsection{Typed subtree swapping in greater detail}
\label{typed-swapping}

First thing to do in standard subtree swapping is to select random node
in the first parent. 

We modify this procedure so that we allow
selection only of those nodes with such a type that there exists  
a node in the second parent with the same type.

Standard subtree swapping crossover as a first thing selects 
whether the selected node will be inner node (usually with probability 
$p_{ip} = 90\%$) or leaf node (with probability 10\%).

We are in a more complicated situation, because one of those 
sets may be empty, because of allowing only nodes with possible "partner"
in the second parent. Thus we do this step only if both sets are
nonempty. 

After selecting a node in the first parent we select node in the
second parent such that type of that node must by the same as the type 
of the first node. Again, this may eliminate the "90-10" step of
first deciding whether the selected node will be internal node 
or leaf node.

When both nodes are selected we may swap the trees. \\

If the abstraction elimination was performed, then 
since the trees are of the same type and there are no variables to be 
moved from their scope, the offspring trees are well typed.\\


Both \sexprTree and \atTree are able to be crossed by this 
mechanism. But \atTree has more possibilities then \atTree.
This comes from the fact that every subtree of the \sexprTree
corresponds to a subtree of \atTree, but there are subtrees
of \atTree that do not correspond to a subtree of a \sexprTree.\\

Following example should clarify this.

\Tree[.@	
   [.@ \textbf{f} x ]
   [.y ]  		 			
]
\Tree[.\textbf{f} x y ]~\\

In \atTree, \textbf{f} is leaf thus subtree, 
whereas in \sexprTree it is internal node thus not a subtree.\\ 

Another nice property of \sexprTree{}s with no lambdas 
is that they are the same representation as S-expressions
used by standard GP.\\

Again, similarly as for standard version, 
a maximum permissible depth $D_{created}$ 
for offspring individuals is defined (e.g. $D_{created} = 17$).
If one of the offspring has greater depth than this limit, then 
this offspring is replaced by the first parent in the result of 
the crossover operator. If both offspring exceeds this limit, than 
both are replaced by both parents.  

For \atTree the $D_{created}$ must be larger since
\atTree (without lambdas) is a binary tree. This 
enlargement is approximately proportionate to average number of 
function arguments. We use generous $D_{created} = 17\times3$. 






\section{Experiments}
\label{experiments}

\section{Conclusions}
\label{conclusions}

TODO

\red{mimojiné zmínit, že v budouznu bysme chtěli porovnat kombinátory 
s tou naší nějak extenzivně, ikdyž možná to tam vubec nepsat
(což by bylo hezký už ted ale nestíhá se to..)}


%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%\section{Osnova}
%\begin{lizt}
%& Jak reprezentovat stromy programu pro GP?
%  && Reprezentace v klasickym kozovy je S-expression.
%  && Nebo mužem používat kombinátory jako 
%     Briggs a O’Neil (to si myslim je jakoby 
%     hlavní konkurence, vuči který by to chtělo obhájit)
%  && Lambda termy a jejich awesomeness
%& \textbf{Povídaní o redukcích}
%& Povídání o lnf
%  && že lnf je přirozený rozšíření s-exprešnu do lambda 
%     kalkulu vlastnosti termu v lnf 
%     &&& proč je eta redukovat (eta redukcí lnf dostanem 
%         beta-eta-nf a že nemusíme beta redukovat pač se to tim nerozbyje)
%& Generování
%  && Generování gramatikou
%  && Gramatika pro lnf
%  && (?) Inhabitation trees jako intuitivní model takovýhodle lnf generování
%& Problémy s proměnýma a jak je řešit.
%  && Křížit lambda termy i s proměnejma a abstrakcema, 
%     problémy řešit když nastanou (pomluvit a odsoudit)
%  && Zmenšit prostor termu (tim že někerý nejsme schopný 
%     vygenerovat) s kterým operujeme tak aby křížení už 
%     nebyl problém (to dělá Yu - v těle lambda fce dovoluje 
%     jen použití proměnných z její hlavy)
%  && Převod hned po vygenerování
%  && Převod až při křížení
%     &&& eliminace abstrakcí
%     &&& skřížim
%     &&& vložený kombinátory nahradim odpovídajícím termem
%     &&& celý to redukuju
% & Pokusy (?!)
% & Závěr
%\end{lizt}


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{evogp}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%


% That's all folks!
\end{document}
