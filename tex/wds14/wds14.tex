%to be compiled with LATEX 2e
%use this setting with 11pt basic font:
\documentclass[11pt]{article}

% >>>>>>>>>>>>>>>>>>    nezapomen projet ze nezbyli zadny TODO      <<<<<<<


\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{xspace}
\usepackage[ampersand]{easylist}
\usepackage{qtree}
\usepackage{color}

%



\usepackage{wds11,epsf}
%use this setting with 10pt basic font:
%\documentclass{article}
%\usepackage{wds10,epsf}
%use to get author-year citations with BibTeX
\usepackage[square]{natbib}


\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}


\newcommand{\Lets}{Let us\xspace}
\newcommand{\lets}{let us\xspace}
\newcommand{\lterm}{$\lambda$-term\xspace}
\newcommand{\lterms}{$\lambda$-terms\xspace}
\newcommand{\lhead}{$\lambda$-head\xspace}
\newcommand{\lheads}{$\lambda$-heads\xspace}
\newcommand{\myla}{\leftarrow\xspace}
\newcommand{\Lp}  {\Lambda^{\prime}\xspace}
\newcommand{\tur}[3]{#1\vdash{}#2 \colon #3}
\newcommand{\turst}[3]{$#1\vdash{}#2:#3$\xspace}
\newcommand{\GMS}{\turst{\Gamma}{M}{\sigma}}
\newcommand{\atTree}{@-tree\xspace}
\newcommand{\setDots}[2]{ \lbrace #1 , \dots , #2 \rbrace}
\newcommand{\lh}[1]{\lambda #1}
\newcommand{\sexprTree}{sexpr-tree\xspace}
\newcommand{\SexprTree}{Sexpr-tree\xspace}
\newcommand{\then}{\Rightarrow\xspace}
\newcommand{\lamb}[2]{( \lambda \, #1 \, . \, #2 )}
\newcommand{\lam}[2]{\lambda \, #1 \, . \, #2}
\newcommand{\ST}{\mathop{\mathrm{ST}}}
\newcommand{\FV}{\mathop{\mathrm{FV}}}
\newcommand{\Scomb }{\mathbf{S}}
\newcommand{\Kcomb }{\mathbf{K}}
\newcommand{\Icomb }{\mathbf{I}}
\newcommand{\bbarr}{\twoheadrightarrow_\beta}
\newcommand{\barr}{\rightarrow_\beta}
\newcommand{\beq}{=_\beta}
\newcommand{\eearr}{\twoheadrightarrow_\eta}
\newcommand{\earr}{\rightarrow_\eta}
\newcommand{\eeq}{=_\eta}
\newcommand{\bearr}{\rightarrow_{\beta\eta}}
\newcommand{\bbeearr}{\twoheadrightarrow_{\beta\eta}}
\newcommand{\beeq}{=_{\beta\eta}}
\newcommand{\etar}{\twoheadrightarrow_\eta}
\newcommand{\ered}{$\eta$-reduction\xspace}
\newcommand{\bnf}{$\beta$-\textit{nf}\xspace}
\newcommand{\enf}{$\eta$-\textit{nf}\xspace}
\newcommand{\eenf}{$\eta^{-1}$-\textit{nf}\xspace}
\newcommand{\beenf}{$\beta\eta^{-1}$-\textit{nf}\xspace}
\newcommand{\benf}{$\beta\eta$-\textit{nf}\xspace}
\newcommand{\bredex}{$\beta$-redex\xspace} 
\newcommand{\lnf}{\textit{lnf}\xspace}
\newcommand{\Ae}{\mathop{\mathrm{AE}}} %{\mathop{\mathrm{\AE}}}
\newcommand{\Bcomb }{\mathbf{B}}   
\newcommand{\BBcomb }{\mathbf{B*}}
\newcommand{\Ccomb }{\mathbf{C}}   
\newcommand{\CCcomb }{\mathbf{C'}}
\newcommand{\SScomb }{\mathbf{S'}}
\newcommand{\ar}{\rightarrow\xspace}
\newcommand{\T}{\mathbb{T}\xspace}
\newcommand{\C}{\mathbb{C}\xspace}
\newcommand{\Real}{\mathbb{R}}

\newcommand{\gar}{\longmapsto}
\newcommand{\bRedex}{$\beta$-redex\xspace}
\newcommand{\bRedexes}{$\beta$-redexes\xspace}
\newcommand{\bArrow}{\rightarrow_\beta\xspace}
\newcommand{\eArrow}{\rightarrow_\eta\xspace}
\newcommand{\eeArrow}{\rightarrow_{\eta^{-1}}\xspace}

\newcommand{\HM}{Hindley–Milner\xspace}


\newenvironment{todo}
{~\\ {\color{red}\textbf{TODO}}
  \begin{easylist}[itemize]}
{ \end{easylist}}

\newcommand{\Lpr}{\Lambda^\prime}
\newcommand{\ul}[2]{\langle #1 ; #2 \rangle}
\newcommand{\ro}[1]{{\color{blue} #1}}
\newcommand{\tom}[1]{{\color{ForestGreen} #1}}
\newcommand{\red}[1]{{\color{red} #1}}




%\tighten

% Preamble Information


%%%%%%%%%%% nevim co to tu bylo za omg, tak jsem to zakomentoval
\lefthead{K\v{R}EN}
\righthead{Typed Genetic Programming in Lambda Calculus with Type Classes}

\setcounter{secnumdepth}{0}

\begin{document}

\setlength{\pdfpagewidth}{210mm}
\setlength{\pdfpageheight}{297mm}


\title{Typed Genetic Programming in Lambda Calculus with Type Classes}

\author{T. K\v ren}

\affil{Charles University, Faculty  of  Mathematics  and  Physics,
     Prague, Czech Republic.}


\begin{abstract}
Genetic programming (GP) traditionally uses simple S-expressions to represent programs. Lambda calculus representation of programs offers a more expressive alternative, which can exhibit better results. Moreover, lambda calculus representation can benefit from a considerable theoretical background. The crucial decision behind the design of a typed GP system is the choice of the underlying type system. The majority of such systems uses \HM (HM) type system. And there are also experiments with System F, which is a generalization of HM. In this paper we outline a novel typed GP system  based on HM enriched with the concept of type classes -- an alternative way to generalizing HM. We discuss its benefits and connection to logic programming. 
\end{abstract}

%\red{TODO\\~[Článek zatím obsahuje i české poznámky, které jsou hodně hala bala a neformální. A celkově je to ještě dost neučesané. Dost jsem zápasil s nedostatkem místem a hodně toho dal pryč, protože jsem dal radši přednost podrobnějšímu popisu klíčových pojmů.. ]}


\begin{article}

\red{\textbf{TODO:: Přidat názorné příklady ...a par dalších poznámek}

Základní příklad, který by se mohl táhnout napříč textem jsou seznamy. Můžeme ukázat, jak v simply typed LC je potřeba pro každý typ seznamu (seznam čísel, znaků, boolů) přidat zvlášť atomický typ, zatímco v HM to jde udělat díky polymorfizmu najednou. Ale pro specializovanější datovou strukturu \textbf{seznam pevné délky} je už HM slabý a každá delka se musí definovat zvlášť (problém je že potřebuju typ stojící za konkrétní číslo, a že typ seznamového konstruktoru musí v sobe obsahovat omezení, že vzniklý list je o jedna delší než ten z kterého vznikl přidáním prvku, což jde v HM těžko vyjádřit, protože máme jen "funkční symboly" ale žádný "predikáty".) ...a to je podobnost s předchozím omezením (v LC musim dělat zvlášť typy seznamů, tady zas zvlášť dýlky). 

Další příklad, který myslím hezky ilustruje moc TC a přitom neni moc komplikovaný je udělat dědičnost pomocí TC.

Další příklad (navíc i příklad na "blackboxing") je "plánování jako special case typovanýho GP s TC" ale to je dost komplikovaný vysvětlit srozumitelně a zároveň stručně, takže to asi ne.

A samozřejmě přichází výhoda v použití toho k čemu se používaj TC v Haskellu prakticky tzn. různý monády, arrows, funktory, atd. 
%Např monáda je definovaná dvěma funkcema (>>= a return), ale pro pro každou svou instanci dělá něco komplet zajímavýho a jinýho (na listech "dělá paralelizmus",  ).

Důležitý je zdůraznit, že oproti Systemu F se výrazně nezesložiťuje generující procedura, ale že to tam naopak celkem přirozeně zapadá jako rozšíření (výpočet logického porgramu a generování typovaného stromu v HM jsou skoro stejné procesy), což kontrastuje s tím co dělaj System F lidi, který kvůli komplexitě inference v SF používaj dost nestandardní GP proceduru (i když teda zajímavou). 

Myslim, že je také dobré jasně vymezit rozdíl ve filozofii použití SF a TC: system F jde cestou \textit{vše nechám na GP systému a to včetně definice typů samotných}, zatímco mnou navrhovaný přístup se nese více v duchu: \textit{rozdělme pole působnosti GP systému a programátora ve stylu programování vs meta-programování, GP-systém programuje (skládá funkce do programů) zatímco programátor nachystá vhodnou "knihovnu" a její datové struktury, ty však mezi sebou mohou mít poměrně komplexní vztahy - "programátor meta-programuje logický program (vztahů datových struktur) pomocí typových tříd"}.
}

\section{Introduction}


Genetic programming (GP) represents an efficient method for automatic generating of programs by means of evolutionary techniques~\citep{koza92,koza2003genetic}. Early attempts to enhance the GP approach with the concept of types include the seminal work~\citep{montana95} where the ideas from Ada programming language were used to define a so-called strongly typed GP.   
The use of types naturally leads to enriching S-expressions,
the traditional GP representation of individuals, with concepts from
\textit{lambda calculus}, which is simple yet powerful functional, mathematical, and programming 
language extensively used in type theory. Such attempts has shown to be 
successful \cite{yu01}. 
%\red{TODO}\footnote{\red{možná přesunout do preliminaries k oduvodnění proč na to dem juknout z formal hlediska a říct že $\Gamma$ je dk že to hezky zvoní}}
One of the motivations for using lambda calculus is that it is backed by a considerable theoretical background. From this background we can utilize several useful concepts such as reductions, normalization or abstraction elimination, and use them to enhance the typed GP (TGP).


%Genetic programming (GP) is an AI technique, which falls into broader category of evolutionary algorithms  ---  mataheuristic  search algorithms inspired  by biological evolution by natural selection. GP was developed by John  \cite{koza92}. I dare say many people perceive its beauty in the fact that GP is a computer program  constructing other computer programs with desired properties by breeding them. It is also pretty successful technique in a number of areas \citep{koza2003genetic}. And perhaps that is why GP has become very popular.

%Early attempts to enhance the GP approach with the concept of types include the seminal work~\citep{montana95} where the ideas from Ada programming language were used to define a so-called strongly typed GP. Usage of types naturally opens door to enriching S-expressions, the traditional GP representation of individuals, with concepts from lambda calculus, which is a simple yet powerful functional, mathematical and programming language extensively used in type theory~\citep{yu01}. 


%%  >>>>>>>>>>>>  

%\red{(- ještě něco k tomu že LC je cool pro TGP (taky z článků - nebo diplomky tam to bylo rozebraný ale jen když bude místo) ?)}


In this paper we compare typed lambda calculus approaches to GP known to us with approach we are suggesting as possible alternative. The crucial decision behind the design of a TGP system is the choice of the underlying \textit{type system}.
The majority of such TGP systems uses \textit{\HM type system (HM)}. There are also experiments with more powerful type systems such as System F. An alternative approach we proposse is to use \textit{HM} enriching with the \textit{type classes}.  

%The rest of the paper is organized as follows: \red{TODO}

\section{Basic notions} %\section{Preliminaries}

In this section several useful notions 
%\textit{(GP, LC, STLC, HM, SF, TC)} 
are described.

\subsection{\textit{Genetic programming}}

A problem to be solved is given to GP in the form of a \textit{fitness function}. A fitness function is a function which takes a computer program as its input and  returns a numerical value called \textit{fitness} as an output. The bigger fitness of a computer program is, the better solution of a problem.
GP maintains a collection of computer programs called \textit{population}.  A member of a population is called \textit{individual}. By running GP algorithm evolution of those individuals is performed. Individuals are computer program \textit{expressions} kept as \textit{syntactic trees}. Another crucial input besides fitness function is a collection of \textit{building symbols}. It is a collection of symbols (accompanied with an information about number of arguments; or in the case of the typed GP, this information is the type of the symbol). Those symbols are used to construct trees representing individuals.

%\Lets describe GP algorithm briefly. At the beginning, initial population is generated randomly from the set of building symbols. A step of GP algorithm is stochastic transformation of the current population into the next population. This transformation is given by the choice of genetic operators (e.g. crossover, mutation) and selection mechanism based on individual fitness. The transformation is repeatedly applied for a predefined number of steps (which is called number of \textit{generations}) or until some predefined criterion is met.

\subsection{\textit{Lambda calculus}}
\red{\textit{tuto subsekci zkracovat v případě překročení limitu....}}

\Lets describe a programming language, 
in which the GP algorithm generates individual programs --- the so called \lterms.

\begin{definition}
Let $V$ be infinite countable set of {\it 
variable names}. Let $C$ be set of {\it constant names}, 
$V \cap C = \emptyset$.	 	
Then $\Lambda$ is set of {\it \lterms} defined inductively as follows.
\begin{align*}
x   \in V \cup C  &\then x     \in \Lambda \\
M,N \in \Lambda   &\then (M~N) \in \Lambda 
\textit{~~~~~~(Function application)} \\
x   \in V , M \in \Lambda &\then \lamb{x}{M} \in \Lambda
\textit{~~~~($\lambda$-abstraction)} 
\end{align*}
\end{definition}

\textit{Function application} and 
\textit{$\lambda$-abstraction} are concepts
well known from common programming languages. 
For example, in JavaScript, 
$(M~N)$ translates to expression \texttt{$M$($N$)} and
$\lamb{x}{M}$ translates to expression \texttt{function($x$)\{return $M$;\}}.
In other words, the function application 
corresponds to the act of supplying a function 
with an argument, and
the $\lambda$-abstraction is equivalent to 
\textit{anonymous function}\footnote{Apart from JavaScript, anonymous functions are common e.g. in Python and Ruby, 
they were recently introduced to C++, and they are expected to be supported in Java 8.}.
To ensure better readability, 
$M_1~M_2~M_3~\dots~M_n$ will be an abbreviation for 
$(\dots((M_1~M_2)~M_3)~\dots~M_n)$.
And $\lam{x_1 \dots x_n }{M}$  for
$\lamb{x_1}{\dots\lamb{x_n}{M}\dots}$.

In order to perform computation, there must be some
mechanism for term evaluation. In $\lambda$-calculus there
is a \mbox{$\beta$-reduction} procedure for this reason.
A term of a form $\lamb{x}{M}N$ is called \textit{\bRedex}.
A \bRedex can be $\beta$-reduced to term $M[x:=N]$. 
It is also possible to reduce \textit{subterm \bRedexes}.
In other words, $\beta$-reduction is the process 
of insertion of arguments supplied to a function into 
its body.

\subsection{\textit{Simply typed lambda calculus}}

A \lterm as described above corresponds to a program expression with no type information included. Now we will describe \textit{simple types}. 

\begin{definition}
Let $A$ be set of {\it atomic type names}. 
Then $\mathbb{T}$ is set of {\it types} inductively defined by the following two rules:
(1) $\alpha      \in A  \then   \alpha \in \T$, and
(2) $\sigma,\tau \in \T \then ( \sigma \ar  \tau ) \in \T$.
\end{definition}

Type $\sigma \ar \tau$ is type for functions taking as input
something of a type $\sigma$ and returning 
as output something of a type $\tau$. 
$\tau_1 \ar \tau_2 \ar \dots \ar \tau_n$ is an abbreviation for 
$\tau_1 \ar (\tau_2 \ar (\dots \ar (\tau_{n-1} \ar \tau_n)\dots))$. Such "chain of arrows" types simulate types of functions with multiple (here $n-1$) inputs. 
This technique is called \textit{currying}. One can grasp the trick by considering $(f~M_1~\dots~M_n)$ as shorthand for $f(M_1,\dots,M_n)$
and by observing that functions with such types have terms of the form $\lam{x_1 x_2 \dots x_n }{M}$. 
The \textit{type system} called \textit{simply typed $\lambda$-calculus (STLC)} is now easily obtained by combining the previously defined \textit{\lterms} and \textit{types} together. 

\begin{definition} Let $\Lambda$ be set of {\it \lterms}. 
	Let $\mathbb{T}$ be set of {\it types}.       
	A {\it statement} $M : \sigma$ is a pair 
	$(M,\sigma) \in \Lambda \times \mathbb{T}$.
	Statement $M : \sigma$ is vocalized as 
	{\it "$M$ has type $\sigma$"}.
	The term $M$ is called the {\it subject} of the 
	statement $M : \sigma$.
A \textit{declaration} is a statement 
 $x : \sigma$ where $x \in V \cup C$.
A \textit{context} 
 is set of declarations with distinct variables as subjects.
\end{definition}
%~\\



Context is a basic type theoretic concept suitable as a typed alternative
for terminal and function set in standard GP. 
Notation $\Gamma,x:\sigma $ denotes $ \Gamma\cup\{(x:\sigma)\}$ 
such that $\Gamma$ does not contain any declaration with $x$ as subject.
We also write $x:\sigma \in \Gamma$ instead of $(x,\sigma) \in \Gamma$.


\begin{definition}
A statement $M\colon\sigma$ is \textit{derivable from}
a context $\Gamma$ (notation 
\mbox{$\Gamma\vdash{}M\colon\sigma$}) 
if it can be produced by the following rules.
\begin{align*}
x : \sigma \in \Gamma &~\then~ \tur{\Gamma}{x}{\sigma}\\
\tur{\Gamma}{M}{\sigma \ar \tau}~,~\tur{\Gamma}{N}{\sigma} 
&~\then~ \tur{\Gamma}{(M~N)}{\tau}\\  
\tur{\Gamma,x:\sigma}{M}{\tau}
&~\then~ \tur{\Gamma}{\lamb{x}{M}}{\sigma \ar \tau} 
\end{align*}
\end{definition}

Those rules are called \textit{inference rules} (see the similarity with the \textit{definition 1}). A type system is defined by a collection of inference rules. When generating terms (e.g., during population initialization) our goal is to produce terms $M$ for a given pair $\ul{\tau}{\Gamma}$ such that for each $M$ is $\tur{\Gamma}{M}{\tau}$ (where $\tau$ is the desired type of generated individuals and $\Gamma$ is the set of \textit{building blocks}). 
More complex type systems (e.g. \HM or System F) can be defined similarly by specifying their set of inference rules, but (for the sake of brevity) we prefer to continue the overview in a less formal fashion.


\subsection{\textit{\HM type system}}

\HM type system \citep{hindley1969principal} is a generalization of the simply typed lambda calculus extended by two concepts: parametric types and type variables (and with the \texttt{let} expression, but we omit its discussion since it is less important for the type related matter).

Parametric types are types that take other type(s) as parameter. E.g., a list (or a tree) of values of the same type. 
A type variable is a type that may stand for an arbitrary type. 
Those two concepts play nicely together, we can see this by observing following simple example. The function \texttt{head} which returns the first element of a list. This function has type \texttt{a -> List a}, where \texttt{a} is a type variable and \texttt{List} is a parametric type (taking another type as parameter, in this case it is a type variable \texttt{a}). In STLC we must define the head function for every concrete instance of the List, whereas in the \HM we can define them all at once. 
 
%možná líp na ... replicate :: Int -> a -> [a]

\subsection{\textit{System F}}

System F \red{\citep{TODO}} can be seen as a further generalization of both STLC and \HM. 
The concept of type variables brings the question of variable quantification. 
\HM uses implicit general quantification. System F is about making things explicit.
This holds both for placing variable quantification symbols ($\forall$) explicitly inside the type terms, and for need to explicitly place the type term into the polymorphic function in order to cast it to the specific instance with no type variables. This for example enables possibility of generating "anonymous" type definitions\footnote{E.g., the standard \texttt{List a = Cons a (List a) | Nil} can be expressed "anonymously" as $\forall \alpha \forall \beta : (\alpha \ar \beta \ar \beta) \ar \beta \ar \beta  $.}. This rise in power brings the disadvantage of the substantially more computationally complex term generating procedure. 

\subsection{\textit{Type classes}}

A type class is a type system construct that supports ad-hoc polymorphism in a mathematically elegant way. The concept of the type class first appeared in the Haskell programming language \citep{morris2013type} and was originally designed as a way of implementing overloaded arithmetic and equality operators in a systematic fashion \citep{wadler1989make}.

Basically a type class is a predicate over types. Let us demonstrate this notion on the simple example of a type class, the \texttt{Eq} type class for handling the equality operator: 

Let \texttt{isMemberInt : Int -> [Int] -> Bool} be a function performing check whether an integer (the first argument) is a meber of a list of integers (the second argument). And let us assume that this function in its definition uses the equality operator:
\texttt{~\\
%isMemberInt :: Int -> [Int] -> Bool\\
isMemberInt y [] = False\\
isMemberInt y (x:xs) = (x == y) || isMemberInt y xs} 

In order to overcame the need to have for each type (such as \texttt{Int}) a specific instance of the function it would be nice to have a way to specific 
a function such as \texttt{member :: a -> [a] -> Bool}, but there is a trouble with
the equality operator used in the definition. The \texttt{==} is defined only on some types. 
The fact that an equality operator is defined for type \texttt{T} is denoted by use of the \textit{predicate} \texttt{Eq} by writing \texttt{(Eq T)}.  
We can specify this additional requirement in the type as \texttt{member :: (Eq a) => a -> [a] -> Bool}. 

Such a predicate is called \textit{type class} and is defined in the following way:

\texttt{class Eq a where (==) :: a -> a -> Bool}.

In order to state the fact that a certain concrete type (e.g. \texttt{Int}) is a type for which the predicate holds we write the following declaration (and suppose that \texttt{eqInt :: Int -> Int -> Bool} is our implementation of integer equality):

\texttt{instance Eq Int where (==) = eqInt}

\red{Co kdybychom ale chtěli definovat Eq nad parametrickým typem, řekněme nad stromem. Jak se vyhneme tomu abychom nemuseli deklarovat instanci pro každý typ seznamu zvlášť? K tomu nám poslouží následující notace (where we omit the implementation part since we are interested in the signature):}

\texttt{instance (Eq a) => Eq (Tree a) where ...}


%\texttt{~\\
%instance (Eq a) => Eq (Tree a) where\\ 
%  Leaf a         == Leaf b          =  a == b\\
%  (Branch l1 r1) == (Branch l2 r2)  =  (l1==l2) \&\& (r1==r2)\\
%  \_              == \_               =  False\\}

\red{v rychlosti okomentovat a zmínit že obecně těch předpokladů tam může bejt víc a jakou to má notaci. řict že pro nás je z typovýho hlediska podstatná ta deklarace a to co následuje po where už je otázka implementace }


%\red{- naznačit celou hierarchii, řict že na vršku je jakoby DTT.}

\section{Related work}
\label{related}

\red{Todo, přepsat aby to pasovalo na porovnání s type classama; připadně to porovnání udělat celý až v následující sekci o our approach, ocitovat krátce kdo ukázal na propojení TC a LP a možnost programovat v typovym systému}


\cite{yu01} presents a GP system utilizing
polymorphic higher-order functions\footnote{Higher-order 
function takes another function as an input parameter.
} and lambda abstractions.
Important point of interest in this work is use of \texttt{foldr}\footnote{ In the functional programming language Haskell \texttt{foldr} can be defined as:\\ \texttt{foldr f z [] $~~~$  = z\\ 
foldr f z (x:xs) = f x (foldr f z xs) }} function as a tool for \textit{implicit recursion},
i.e. recursion without explicit recursive calls. 
The terminal set for constructing lambda abstraction subtrees 
is limited to use only constants and variables of that particular
lambda abstraction, i.e., outer variables are not allowed to be used
as terminals in this work. This is significant difference from our approach 
since we permit all well-typed normalized \lterms. From this difference also
comes different crossover operation. We focus more on term generating process; 
their term generation is performed in a similar way as the standard one, 
whereas our term generation also tries to utilize techniques of systematic enumeration. 

\cite{kes} present technique 
utilizing typed GP with combinators.
The difference between approach presented in this work
and our approach is that in this work terms are generated
straight from \textit{library} of combinators and no lambda abstractions
are used. They are using more general polymorphic type system than us
-- the Hindley–Milner type system. They also discuss the 
properties of exhaustive enumeration of terms and compare it with GP search.  
They also present interesting concept of \textit{Generalized
genetic operator} based on term generation. 

\cite{binard2008genetic} use even 
stronger type system (\textit{System F}).  
But with increasing power of the type system comes increasing difficulty of term generation.
For this reason evolution in this work takes interesting and nonstandard shape 
(fitness is associated with \textit{genes} which are evolved together with \textit{species}
which together participate in creation of individuals).
This differs from our approach, which tries to be generalization of
the standard GP\citep{koza92}.

In contrast with above mentioned works our approach uses very simple type system 
(simply typed lambda calculus) and concentrates on process of generation  
able to generate all possible well-typed normalized lambda terms. In order to do
so we use technique based on \textit{inhabitation machines} 
described by Barendregt \cite{barendregt10}.    




%%% Abych věděl jak citovat tak sem si tu kousek nechal
%The interaction of the solar wind with the Earth's magnetosphere
%generates a population of backstreaming ions directed from the
%bow shock into the solar wind. This high-energy population was
%invoked to explain Hot Flow Anomalies (HFAs)
%\citep[e.g.][]{sw}. \citet{th} identified as heated regions of solar wind plasma
%flowing nearly perpendicular to the Earth-Sun line.
%The main observational features of HFAs include \citep[and others]{sw}: (1) Central regions with hot plasma flowing
%significantly slower than that in the ambient solar wind in a
%direction highly deflected (nearly $90^o$) from the Sun-Earth line.
%The flow velocities are often roughly tangential to the nominal
%bow shock shape \citep{sw}.
%(2) HFAs are bounded by regions of enhanced
%magnetic field strength, density, and temperature. The outer
%edges of these enhancements are fast shocks generated by
%pressure enhancements within the core region. The inner
%edges of the enhancements are probably  tangential
%discontinuities.
%Published examples indicated that  many HFAs are bounded by only
%one enhancement.
%(3) HFAs occur in conjunction with significant changes in the IMF
%direction. The angle between pre- and post event orientations is
%typically $\sim 70^o$.


\section{Our approach}

\red{následující dvě subsekce (generování, křížení) pojmout tak, aby řekli: oporti obecnému trendu se my  zatim soustředíme výrazně víc na generující proceduru (než na operátory atd jak bejvá zvykem) a pojímame jí jako kontinuum od klasického GP přístupu až k systematické enumeraci bližšší automatickému dokazování. Uvidíme že tento přístup nám napomáhá hladce integrovat výpočet logického porgramu stojícího za soustavou typovejch tříd do generující procedury. }

%\red{In our previous work jsme se rozhodli pro přístup: nejdřív vzít nejjednoduší typovej systém a v něm navrhnout generování a gen operace tak aby jednak byly zobecnění std GP, a jednak aby byly schopný generovat libovolnej term (modulo NF), ne jen nějakou jednodušší podmnožinu.

%Pokud se to tam vejde tak zmínit, že HM lze z STLC získat tak že (zjednodušeně řečeno) na vhodných mistech změníme porovnání rovnosti typových termů za unifikaci typových termů. (V tý nasledující sekci pak k tomu navíc přidat, že se k unifikaci přidává běh logickýho programu, který je ale nutno pouštět po krokách tak, aby byly na stejný urovni kroky generujícího algoritmu a kroky běhu toho LP (tzn že rozpracovaný term muže být několik kroků A* v tom samém termu ale s jiným stádiem dopočítanosti logického programu pracujícího na doplnění dalšího symbolu). )

%Konkretní popis mojí generující (a křížící) metody zatim zakomentován protože to zabírá moc místa, nejdřív dopsat zbytek a pak vzít co se vejde, pokud vůbec něco..}



\subsection{\textit{Generating}}

Our approach to \lterm generating is based on technique briefly described in \citep{barendregt10}, which generates well-typed \lterms in their \textit{long normal form}. 

Our generating method is based on simple modification of the standard A* \citep{AIMA}, which we call \textit{forgetful A*}. This modification consist in additional parameter for the A* algorithm -- the \textit{search strategy}. It is a simple filtration function that is given the set of all successors of the state that is being examined and returns a subset of this input. This subset is added to the priority queue to be further explored. In this way the search space may be reduced as the filtration function may \textit{forget} some successors.

A* keeps a priority queue of states during the generation process, on the other hand the \textit{ramped half-and-half method}, the standard GP algorithm for generating individuals, keeps only one individual which is gradually constructed. This behavior is easily achieved by use of suitable search strategy that returns subset consisting of only one successor. The systematic exhaustive search is obtained by search strategy that returns whole input set. Our novel \textit{geometric strategy} can be understood as point somewhere between those two extremes.


%%.... metaevoluce remark
%%A remarkable benefit of parameterizing the generating method by a search strategy taking the form of a simple filtration function is that such a function can be expressed by functional language in a very economical way. Take for instance a search strategy that behaves same as the \textit{geometric} except that when it comes to situation where all the elements are filtered out it acts as the \textit{ramped half-and-half}. Such \textit{strategy composition} is easily describable as a higher order function. Thus comes to mind the possibility of using our system to come up with new search strategies on its own.


\subsection{\textit{Crossover}}

Our system utilizes generalization of the standard tree-swapping crossover operator. Two main concerns with swapping typed subtrees are types and free variables. Well-typed offspring is obtained by swapping only subtrees of the same type. Only subtrees with corresponding counterpart in the second parent are randomly chosen from. More interesting problem lies in free variables, which may cause trouble if swapped somewhere where it is suddenly not bounded. In order to circumvent this difficulty we utilize technique called \textit{abstraction elimination}\citep{jones87} that transforms an arbitrary \lterm into \lterm that contains no lambda abstractions and no bound variables. After the initial population is generated,  it is transformed by abstraction elimination. Another possible transformation taking place after initialization is $\eta$-normalization shortening rather long long normal form into shorter $\beta\eta$-normal form.  

Another performance enhancing transformation is option of using "applicative" tree representation (coming directly from inductive definition of \lterms) instead of more traditional S-expression representation. Favorable properties of applicative tree representation are also reported in \citep{yu1998polygp}. 

\section{\textit{Using \HM with type classes}}

%\red{Jak pojmout podstatu článku? Řekl bych, že vtip je v použití typovejch tříd na hendlování typovýho systému TGP. Tahle pasáž je imho klíčová a tak bych jí napsal jako první, podle noušnů v ní obsaženejch bych pak upravil preliminaries a akordingly to zmínil v related work na konci (něco jako, na rozdíl od kanaďanů my se chceme skusit vydat na cestu k zobecnění HM tak, že využijem typeclasses : výhody videíme v tom, že se prakticky využívaj haskellu a jejich použití výrazně neztěžuje inferenční proces, naopak do něj přirozeně pasuje)}

%\red{nekde dyštak zmínit že to jsou fikaný javovský interfacy}





Jak TC převést do GP? Konkrétněji jak generovat programy v HM rozšířeném o TC?
Pro generování bez TC je potřeba zadat požadovaný typ a mn. stavebních symbolu (s informací o jejich typech) tj. context. Pro HM s TC musíme navíc zahrnout deklarace tříd a instancí.

Deklarace tříd udává jednak podmínky které musí splnit deklarace instancí. Navíc pokud používáme TC Eq, je patrně nasnadě aby součástí contextu byly funkce, které daná třída definuje. E.g., pro smysluplné použití třídy Eq je potřeba aby součástí vstupniho contextu bylo \texttt{(==) :: (Eq a) => a -> a -> Bool}. 

Hlavní novinku do vstupu generujícího algoritmu zajišťují deklarace instancí.  
Množina instancí nám  v záseadě přidává informaci o struktuře typů, nad kterými operují funkce z kontextu.

Pro účely generování nás zajíma jen "info z prvního řádku", v zasadě máme dva typy instancí jednoduchou a s předpoklady. Zásadním faktem je, že tyto informace o instancích můžeme přímočaře vyjádřit jako logické programy \red{citovat něco kde se to dělá}. 

\texttt{instance $P$ $T$ where ...} odpovídá faktu $P(T)$.

\texttt{instance ($P_1$ $T_1$,$\dots$,$P_n$ $T_n$) => $P$ $T$ where ...} odpovídá hornovské klauzuli $P(T) \leftarrow P_1(T_1),\dots,P_n(T_n)$.

Pro přehlednost jsme uvedli predikátové symboli jen s jedním argumentem, přímočaře to však můžeme zobecnit pro predikáty libovolné arity.

Odpověď na otázku zda daný typ je instancí nějaké TC zodpovíme odpovídajícím dotazem pro logický program odpovídající naší množině instancí.


\red{
- říct že sou 2 použití - jednak v původnim smyslu pro ad-hoc polymorphism - ale taky exploitačnim způsobem kde nám vůbec nejde o implementační složku (která může být prázdná), ale jde nám jen o LP věci. Názornym příkladem takovýho použití je zavedení čísel (pozor neplest s termovými čísly) do typovýho systému.

- taková čísla se nám mohou hodit např při práci se seznamy pevné délky.

- dodat tuto LP složku je na programátarovy, GP se pak stará o generování. 
  TC jsou ale obecné konstrukty které jde jednoduše používat napříč problémy
  (užití Systému F naopak nechává vše na GP, minimum na programátorovi) 

- neboť LP tur completní tak v zasadě můžeme naprogramovat libovolnej predikát

- blackboxing - nemusíme se trápit s tím pracně definovat predikáty v LP, stačí když se budou zvenku chovat tak jako by byli a vevnitř mohou bejt napsaný třeba v javě

- když zbude místo (což se asi nestane) tak tmínit příklad blackboxingu - plánování vyjádřený vjako specialní případ typovanýho GP. Spíš asi než takle komplikovanej příklad dát ale na víc míst par drobnejch příkladů využití

- určitě shrnout výhody HM+TC approache...

%- praktický příklad takovýho blackboxingu - např plánování. ukazuje, že tyto dvě problem solving approaches are uzce connected - využití např že se muže GP inspirovat technikama z Planování, naopak zas že type theory může dát plánování expresivní jazyk / novej pohled na pro škatulkizaci různejch pojmů co odpovídaj nějakejm věcem co v GP jsou přirozeně (fce víc argumentů..., lamb abstr...)

%- nakonec (/na začatek) zmínit že máme i další future worky ale že vybíráme tento konkrétní
}

%\section{Starší poznámky ...}
%
%- HM .. místo = dá unifikaci, a bez letu.
%
%(možná tam dát dk, spiš ne)
%
%- uvod k hm+tc 1-3 věty.

%\subsection{hinley milner + type classes}
%
%příklady
%
%(možná i ten s planovanim, dle času a místa)
%
%(metaevoluce)

%\subsection{Problémy}
%
%- sada benchmarku - citovat ten šit co sem našel
%
%- trhy
%
%. - vyhody: propojenej uzel uloh (slechteni manazera, modelu, konstruktera stroju, ), je to vypocetni model, na trh muzeme koukat jako na 
%. - meta model - výpočetní model co má to co optimalizuje zakodovany jako komoditu to co 
%. - navazuje na spolupráci mezi plánovánim a 

\section{Conclusions}
Todo nebo spojit s future work do jedný subsekce.


\red{v referencích změnit toho barendrechta na toho z roku 2013}

% TODO nemaj se tam dát TODO
%\acknowledgments %\footnotesize
%{???}


\bibliographystyle{egs}%<-- LIST OF REFERENCES TO BE IN "EGS" STYLE (FILE "EGS.STY")
\bibliography{my}       %<-- REFERENCES ARE IN FILE "SAMPLE.BIB"

\end{article}
\end{document}

