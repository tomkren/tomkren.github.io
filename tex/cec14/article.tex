\documentclass[conference]{IEEEtran}


\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{xspace}
\usepackage{amsmath}

\usepackage{graphicx}
\usepackage{epstopdf}

\usepackage[ampersand]{easylist}
\usepackage[usenames,dvipsnames]{color}




%\usepackage[ruled,norelsize]{algorithm2e}
\usepackage[vlined,ruled,norelsize]{algorithm2e}


\newcommand{\Pseudokod}[3]{
	\begin{figure}[!t]
	\removelatexerror
	\begin{algorithm}[H]
		\caption{#1}
		\DontPrintSemicolon
		\SetKwProg{Fn}{function}{}{}
		\Fn{#2}{#3}
	\end{algorithm}
	\end{figure}
}

\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother



\newtheorem{definition}{Definition}

\newenvironment{lizt}
{\begin{easylist}[itemize]}
{\end{easylist}}

\newcommand{\Lets}{Let us\xspace}
\newcommand{\lets}{let us\xspace}
\newcommand{\lterm}{$\lambda$-term\xspace}
\newcommand{\lterms}{$\lambda$-terms\xspace}
\newcommand{\lhead}{$\lambda$-head\xspace}
\newcommand{\lheads}{$\lambda$-heads\xspace}
\newcommand{\la}{\leftarrow\xspace}
\newcommand{\Lp}  {\Lambda^{\prime}\xspace}
\newcommand{\tur}[3]{#1\vdash{}#2 \colon #3}
\newcommand{\turst}[3]{$#1\vdash{}#2:#3$\xspace}
\newcommand{\GMS}{\turst{\Gamma}{M}{\sigma}}
\newcommand{\atTree}{@-tree\xspace}
\newcommand{\setDots}[2]{ \lbrace #1 , \dots , #2 \rbrace}
\newcommand{\lh}[1]{\lambda #1}
\newcommand{\sexprTree}{sexpr-tree\xspace}
\newcommand{\SexprTree}{Sexpr-tree\xspace}
\newcommand{\then}{\Rightarrow\xspace}
\newcommand{\lamb}[2]{( \lambda \, #1 \, . \, #2 )}
\newcommand{\lam}[2]{\lambda \, #1 \, . \, #2}
\newcommand{\ST}{\mathop{\mathrm{ST}}}
\newcommand{\FV}{\mathop{\mathrm{FV}}}
\newcommand{\Scomb }{\mathbf{S}}
\newcommand{\Kcomb }{\mathbf{K}}
\newcommand{\Icomb }{\mathbf{I}}
\newcommand{\bbarr}{\twoheadrightarrow_\beta}
\newcommand{\barr}{\rightarrow_\beta}
\newcommand{\beq}{=_\beta}
\newcommand{\eearr}{\twoheadrightarrow_\eta}
\newcommand{\earr}{\rightarrow_\eta}
\newcommand{\eeq}{=_\eta}
\newcommand{\bearr}{\rightarrow_{\beta\eta}}
\newcommand{\bbeearr}{\twoheadrightarrow_{\beta\eta}}
\newcommand{\beeq}{=_{\beta\eta}}
\newcommand{\etar}{\twoheadrightarrow_\eta}
\newcommand{\ered}{$\eta$-reduction\xspace}
\newcommand{\bnf}{$\beta$-\textit{nf}\xspace}
\newcommand{\enf}{$\eta$-\textit{nf}\xspace}
\newcommand{\eenf}{$\eta^{-1}$-\textit{nf}\xspace}
\newcommand{\beenf}{$\beta\eta^{-1}$-\textit{nf}\xspace}
\newcommand{\benf}{$\beta\eta$-\textit{nf}\xspace}
\newcommand{\bredex}{$\beta$-redex\xspace} 
\newcommand{\lnf}{\textit{lnf}\xspace}
\newcommand{\Ae}{\mathop{\mathrm{\AE}}}
\newcommand{\Bcomb }{\mathbf{B}}   
\newcommand{\BBcomb }{\mathbf{B*}}
\newcommand{\Ccomb }{\mathbf{C}}   
\newcommand{\CCcomb }{\mathbf{C'}}
\newcommand{\SScomb }{\mathbf{S'}}
\newcommand{\ar}{\rightarrow\xspace}
\newcommand{\T}{\mathbb{T}\xspace}
\newcommand{\C}{\mathbb{C}\xspace}
\newcommand{\Real}{\mathbb{R}}

\newenvironment{todo}
{~\\ {\color{red}\textbf{TODO}}
  \begin{easylist}[itemize]}
{ \end{easylist}}

\newcommand{\Lpr}{\Lambda^\prime}
\newcommand{\ul}[2]{\langle #1 ; #2 \rangle}
\newcommand{\ro}[1]{{\color{blue} #1}}
\newcommand{\tom}[1]{{\color{ForestGreen} #1}}
\newcommand{\red}[1]{{\color{red} #1}}


\hyphenation{op-tical net-works semi-conduc-tor IEEEtran}

%\IEEEoverridecommandlockouts    % to create the author's affliation portion

\begin{document}


\title{Generating Lambda Term Individuals in Typed Genetic Programming Using Forgetful A*}

\author{\IEEEauthorblockN{Tom\'{a}\v{s} K\v{r}en$^{*\dag}$}
\IEEEauthorblockA{
tomkren@{}gmail.com\\
$^{*}$Charles University\\
Faculty  of  Mathematics  and  Physics\\
Malostransk\'e n\'am\v{e}st\'\i \ 25, Prague\\
Czech Republic}
\and
\IEEEauthorblockN{Roman Neruda$^{\dag}$}
\IEEEauthorblockA{roman@{}cs.cas.cz\\
$^{\dag}$Institute of Computer Science\\
Academy of Sciences of the Czech Republic\\
Pod Vod\'arenskou v\v{e}\v{z}\'\i \ 2, Prague\\
Czech Republic}
}




\maketitle


\begin{abstract}
Tree based genetic programming (GP) traditionally uses simple S-expressions to represent programs, however more expressive representations, such as lambda calculus, can exhibit better results while being better suited for typed GP. In this paper we present population initialization methods within a framework of GP over simply typed lambda calculus that can be also used in the standard GP approach. Initializations can be parameterized by different search strategies, leading to wide spectrum of methods corresponding to standard ramped half-and-half initialization on one hand, or exhaustive systematic search on the other. A novel geometric strategy is proposed that balances those two approaches. Experiments on well known benchmark problems show that the geometric strategy outperforms the standard generating method in success rate, best fitness value, time consumption and average individual size.
\end{abstract}
% no key words

\section{Introduction}
\PARstart{G}{enetic} programming (GP) represents an efficient method for automatic generating of programs by means of evolutionary techniques~\cite{koza92,koza03}. Early attempts to enhance the GP approach with the concept of types include the seminal work~\cite{montana95} where the ideas from Ada programming language were used to define a so-called strongly typed GP.   
The use of types naturally leads to enriching S-expressions,
the traditional GP representation of individuals, with concepts from
lambda calculus, which is simple yet powerful functional, mathematical, and programming 
language extensively used in type theory. Such attempts has shown to be 
successful \cite{yu01}. 

%The key issue in the lambda calculus approach to enrich GP with types is the method of individual generation. 
In this paper we present a tree generating method suitable both for the standard GP~\cite{koza92} and for the typed GP over lambda calculus. We chose to describe the algorithm by means of the typed lambda calculus, since the standard S-expression representation can be understood as a special case of this representation. However, for evaluation of our approach, we focus more on problems from the standard GP domain. The main reason for this is that the result of GP system depends on the crossover operation, which still remains an open problem for the typed GP over lambda calculus.

During the expansion phase of the term generating procedure the space of unfinished terms can be browsed with respect to various search strategies. Our approach to this problem aims to utilize the full arsenal given by the simply typed lambda calculus. Thus, the natural idea is to employ an exhaustive systematic search. On the other hand, if we were to mimic the standard GP approach, a quite arbitrary yet common and successful ramped half-and-half generating heuristic~\cite{fg} should probably be used.  
These two search methods in fact represent boundaries between which we will try to position our parameterized solution that allows us to take advantage of both strategies. This design goal also differentiate our approach from 
the three state of the art proposals for typed GP known to us that are discussed in the following section. 
Our proposed \emph{geometric
%al 
search strategy}\footnote{Not to be confused with geometric  crossover introduced by \cite{moraglio2010}.} described in this paper is such a successful hybrid mixture of random and systematic exhaustive search. Experiments show that it is also very efficient dealing with one of the traditional GP scarecrows -- the bloat problem.

The rest of the paper is organized as follows: The next section briefly discusses related work in the field of typed GP, while section~\ref{preliminaries} introduces necessary notions. Main original results about search strategies in individual generating are described in section~\ref{approach}. Section~\ref{experiments} presents results of our method on three well-known tasks, and the paper is concluded by section~\ref{conclusions}.

\section{Related work}
\label{related}

Yu presents a GP system utilizing
polymorphic higher-order functions\footnote{Higher-order 
function takes another function as an input parameter.
} and lambda abstractions  \cite{yu01}.
Important point of interest in this work is use of \texttt{foldr}\footnote{ \texttt{foldr f z [] $~~~$  = z\\ 
$~~~\;$foldr f z (x:xs) = f x (foldr f z xs) }} function as a tool for \textit{implicit recursion},
i.e. recursion without explicit recursive calls. 
The terminal set for constructing lambda abstraction subtrees 
is limited to use only constants and variables of that particular
lambda abstraction, i.e., outer variables are not allowed to be used
as terminals in this work. This is significant difference from our approach 
since we permit all well-typed normalized \lterms. From this difference also
comes different crossover operation. We focus more on term generating process; 
their term generation is performed in a similar way as the standard one, 
whereas our term generation also tries to utilize techniques of systematic enumeration. 

Briggs and O’Neill present technique 
utilizing typed GP with combinators \cite{kes}.
The difference between approach presented in this work
and our approach is that in this work terms are generated
straight from \textit{library} of combinators and no lambda abstractions
are used. They are using more general polymorphic type system than us
-- the Hindley–Milner type system. They also discuss the 
properties of exhaustive enumeration of terms and compare it with GP search.  
They also present interesting concept of \textit{Generalized
genetic operator} based on term generation. 

Binard and Felty use even 
stronger type system (\textit{System F}) \cite{binard2008genetic}.  
But with increasing power of the type system comes increasing difficulty of term generation.
For this reason evolution in this work takes interesting and nonstandard shape 
(fitness is associated with \textit{genes} which are evolved together with \textit{species}
which together participate in creation of individuals).
This differs from our approach, which tries to be generalization of
the standard GP\cite{koza92}.

In contrast with above mentioned works our approach uses very simple type system 
(simply typed lambda calculus) and concentrates on process of generation  
able to generate all possible well-typed normalized lambda terms. In order to do
so we use technique based on \textit{inhabitation machines} 
described by Barendregt \cite{barendregt10}.    


\section{Preliminaries}
\label{preliminaries}

In this section, several notions necessary to build a typed GP based on lambda calculus are introduced. 
First, \lets describe a programming language, 
in which the GP algorithm generates individual programs --- the so called \lterms.


\begin{definition}
Let $V$ be infinite countable set of {\it 
variable names}. Let $C$ be set of {\it constant names}, 
$V \cap C = \emptyset$.	 	
Then $\Lambda$ is set of {\it \lterms} defined inductively as follows.	
\begin{align*}
x   \in V \cup C  &\then x     \in \Lambda 
\textit{~~~~~~~~~~~~~(Variable or constant)}\\
M,N \in \Lambda   &\then (M~N) \in \Lambda 
\textit{~~~~~~(Function application)} \\
x   \in V , M \in \Lambda &\then \lamb{x}{M} \in \Lambda
\textit{~~~~($\lambda$-abstraction)} 
\end{align*}
\end{definition}

\textit{Function application} and 
\textit{$\lambda$-abstraction} are concepts
well known from common programming languages. 

For example in JavaScript term
$(M~N)$ translates to expression \texttt{$M$($N$)} and
$\lamb{x}{M}$ translates to expression \texttt{function($x$)\{return $M$;\}}.
In other words, the function application 
corresponds to the act of supplying a function 
with an argument, and
the $\lambda$-abstraction is equivalent to 
\textit{anonymous function}\footnote{Apart from JavaScript, anonymous functions are common e.g. in Python and Ruby, 
they were recently introduced to C++, and they are expected to be supported in Java 8.}.
$M_1~M_2~M_3~\dots~M_n$ is an abbreviation for $(\dots((M_1~M_2)~M_3)~\dots~M_n)$
and $\lam{x_1 x_2 \dots x_n }{M}$ for $\lamb{x_1}{\lamb{x_2}{\dots\lamb{x_n}{M}\dots}}$.

A \lterm as described above
corresponds to a program expression with no type information
included. Now we will describe \textit{types} (or \textit{type terms}).

\begin{definition}
Let $A$ be set of {\it atomic type names}. 
Then $\mathbb{T}$ is set of {\it types} inductively defined as follows.
\begin{align*}
\alpha      \in A  &\then   \alpha \in \T \\
\sigma,\tau \in \T &\then ( \sigma \ar  \tau ) \in \T 
\end{align*}
\end{definition}

Type $\sigma \ar \tau$ is type for functions taking as input
something of a type $\sigma$ and returning 
as output something of a type $\tau$. 
$\tau_1 \ar \tau_2 \ar \dots \ar \tau_n$ is an abbreviation for 
$\tau_1 \ar (\tau_2 \ar (\dots \ar (\tau_{n-1} \ar \tau_n)\dots))$. Such "chain of arrows" types simulate types of functions with multiple (here $n-1$) inputs. 
This technique is called \textit{currying}. One can grasp the trick by considering $(f~M_1~\dots~M_n)$ as shorthand for $f(M_1,\dots,M_n)$
and by observing that functions with such types have terms of the form $\lam{x_1 x_2 \dots x_n }{M}$. 


The system called \textit{simply typed $\lambda$-calculus} is now easily obtained by combining the previously defined \textit{\lterms} and \textit{types} together. 

\begin{definition}~

\begin{enumerate}
 \item 	Let $\Lambda$ be set of {\it \lterms}. 
	Let $\mathbb{T}$ be set of {\it types}.       
	A {\it statement} $M : \sigma$ is a pair 
	$(M,\sigma) \in \Lambda \times \mathbb{T}$.
	Statement $M : \sigma$ is vocalized as 
	{\it "$M$ has type $\sigma$"}.
	The term $M$ is called the {\it subject} of the 
	statement $M : \sigma$.
 \item A \textit{declaration} is a statement 
 $x : \sigma$ where $x \in V \cup C$.
  
 \item A \textit{context} 
 is set of declarations with distinct variables as subjects.
\end{enumerate}
\end{definition}
%~\\



Context is a basic type theoretic concept suitable as a typed alternative
for terminal and function set in standard GP. 
Notation $\Gamma,x:\sigma $ denotes $ \Gamma\cup\{(x:\sigma)\}$ 
such that $\Gamma$ does not contain any declaration with $x$ as subject.
We also write $x:\sigma \in \Gamma$ instead of $(x,\sigma) \in \Gamma$.


\begin{definition}
A statement $M\colon\sigma$ is \textit{derivable from}
a context $\Gamma$ (notation 
\mbox{$\Gamma\vdash{}M\colon\sigma$}) 
if it can be produced by the following rules.
\begin{align*}
x : \sigma \in \Gamma &~\then~ \tur{\Gamma}{x}{\sigma}\\
\tur{\Gamma}{M}{\sigma \ar \tau}~,~\tur{\Gamma}{N}{\sigma} 
&~\then~ \tur{\Gamma}{(M~N)}{\tau}\\  
\tur{\Gamma,x:\sigma}{M}{\tau}
&~\then~ \tur{\Gamma}{\lamb{x}{M}}{\sigma \ar \tau} 
\end{align*}
\end{definition}

Our goal in term generation is to produce terms $M$
for a given pair $\ul{\tau}{\Gamma}$
such that for each $M$ is $\tur{\Gamma}{M}{\tau}$.

\begin{definition}
Let $V$ be infinite countable set of {\it 
variable names}. Let $C$ be set of {\it constant names}, 
$V \cap C = \emptyset$.	
Let $\T$ be set of types.
Let $\C$ be set of all contexts on ($V \cup C$, $\T$).
Then $\Lpr$ is set of 
\textit{unfinished  \lterms} defined inductively as follows.	
\begin{align*}
\tau \in \T , \Gamma \in \C &\then \ul{\tau}{\Gamma} \in \Lpr
\textit{~~~~~~~~(Unfinished leaf)}\\
x   \in V \cup C  &\then x     \in \Lpr
\textit{~~~~~~~~~~~~~(Variable or constant)}\\
M,N \in \Lpr   &\then (M~N) \in \Lpr 
\textit{~~~~~~(Function application)} \\
x   \in V , M \in \Lpr &\then \lamb{x}{M} \in \Lpr
\textit{~~~~($\lambda$-abstraction)} 
\end{align*}
\end{definition}


\textit{Unfinished leaf} $\ul{\tau}{\Gamma}$ 
stands for yet not specified \lterm of the type $\tau$ 
build from symbols of $\Gamma$.



\section{Our approach}
\label{approach}

\subsection{Introduction}

%\red{na vhodna mista podotknout, jak to je v std GP}

Our approach to \lterm generating is based on technique 
briefly described in \cite{barendregt10}, which generates
well-typed \lterms in their long normal form. 
We use this technique to perform a systematic exhaustive enumeration
of \lterms in their long normal form in order from the smallest to the largest.
We use well known \textit{A* algorithm} \cite{AIMA} for this task.
A* is used to search in a given state space for a goal state. 
It finds the optimal solution (in our case the smallest term)
and uses "advising" heuristic function.
It maintains a priority queue to organize states yet to be explored.
Initially this queue contains only the initial state.  

Our state space to search in is the space of unfinished \lterms. 
The initial state is the unfinished term $\ul{\tau}{\Gamma}$, 
where $\tau$ is the desired type of
terms to be generated and $\Gamma$ is the context
representing the set of building symbols to be used in construction of
terms (it corresponds to the set $T \cup F$ in
standard GP enriched with types). The process of determining 
successors of a state described below is designed so it constructs well-typed 
\lterms and omits no \lterm in its long normal form. 
A state is considered a goal state if it contains no unfinished
leaf, i.e., it is a finished \lterm.

Our generating method is based on simple modification of the
standard A*, which we call \textit{forgetful A*}. This modification consist in 
additional parameter for the A* algorithm -- the \textit{search strategy}. 
It is a simple filtration function (along with initialization procedure)
that is given the set of all successors of the state that is being examined
and returns a subset of this input. This subset is added to the priority queue 
to be further explored. In this way the search space may be reduced as 
the filtration function may \textit{forget} some successors.
If the queue becomes empty before the desired number of \lterms
is generated, then the initial state is inserted to the queue
and the process continues. For the standard A* this would be meaningless,
but since our A* is forgetful this kind of restart makes sense.

A* keeps a priority queue of states during the generation process,
on the other hand the \textit{ramped half-and-half method}, 
the standard GP algorithm for generating individuals, 
keeps only one individual which is gradually constructed. This 
behavior is easily achieved by use of suitable search strategy 
that returns subset consisting of only one successor.
The systematic search is obtained by search strategy that 
returns whole input set.      
Our novel \textit{geometric strategy} can be understood as
point somewhere between those two extremes.

\subsection{Algorithm}

Let us look on the proposed generating procedure in a grater detail sufficient as guide for implementing it.
The inputs for the term generating algorithm are following:
\begin{enumerate}
 \item Desired type $\tau$ of generated terms.
 \item Context $\Gamma$ representing the set of building symbols.
 \item Number $n$ of terms to be generated.
 \item Search strategy $S$. 
\end{enumerate}

Essential data structure of our algorithm 
is priority queue of unfinished terms. 
Priority of an unfinished term is given by its size\footnote{
A* heuristic function is hidden in method of computing
size of unfinished leafs $\ul{\tau}{\Gamma}$. Our algorithm uses
trivial estimate $\vert\ul{\tau}{\Gamma}\vert = 1$ which is trivially admissible.
This heuristic is not as naive as it might seem since it is
quite usual to have $x$ such that $x : \tau \in \Gamma$.
Since the true value of $\vert\ul{\tau}{\Gamma}\vert$ depends only on
$\tau$ and \textit{types} in $\Gamma$ (the \textit{signature}), 
no matter how many variables/constants of
each type there are, it should by pretty effective to compute this
value precisely and store them for later. 
%This topic has other interesting 
%subtopics (such as surprisingly small 
%number of such "signatures" for a given problem), 
%but it is unfortunately beyond the scope of this paper.
}.
At the beginning, the queue contains only one unfinished term; 
$\ul{\tau}{\Gamma}$. The search strategy $S$ also 
initializes its internal state (if it has one).

At each step, the term $M$ with the smallest size
is pulled from the queue.
According to the number of unfinished leafs in $M$ one of
the following actions is performed:
\begin{enumerate}
 \item If the term $M$ has no unfinished leaf (i.e., it is a finished
 term satisfying \mbox{$\tur{\Gamma}{M}{\tau}$}), then it is added to the
 result set
% \footnote{
% \red{TODO: říct že tim že je to set se řeší problém toho, aby se tam nevyskytovali
% některý vygenerovaný víckrát, pokud však toto nechcem můžem použít jinou collection
% , případně to vůbec nezminovbat když by to kradlo moc místa
% }} 
 of generated terms.   
 \item Otherwise, \textit{successors} of the unfinished term $M$ are
       filtered out by \textit{search strategy} $S$ and
       those successors that outlast the filtration 
       are inserted into the queue.
\end{enumerate}

\textit{Successors} of an unfinished term $M$ are obtained by 
\textit{expansion} of the \mbox{\textit{DFS-first}} unfinished leaf $L$
(i.e., the leftmost unfinished leaf of $M$).

Expansion of the selected unfinished leaf $L$ leads to creation of 
one or many (possibly zero) successors.
In this process, $L$ is replaced
by a new subterm defined by the following rules\footnote{
For the sake of simplicity it is presented as two separate rules. 
Since the first rule results in exactly one successor it is smarter
to combine those two rules into one resulting in that unfinished leafs
have only atomic types. At the beginning we transform the initial type into atomic by first rule (if necessary). After that
only second rule is applied, but if it results in creation of some unatomic 
$\ul{\tau_i}{\Gamma}$, then first rules are applied, but during the same successor creation This step eliminates all unatomic unfinished leafs. }:
\begin{enumerate}
 \item \textit{Function rule:} 
 
 If $L = \ul{\rho_1 \ar \dots \ar \rho_n \ar \alpha}{\Gamma}$,
 	   where $\alpha$ is atomic type and $n \geq 1$, 
       then $L$ is replaced by 
       $\lamb{x_1 \dots x_n}{\ul{\alpha}
       {\Gamma,x_1 \colon \rho_1,\dots,x_n \colon \rho_n}}$.
       Thus this expansion results in exactly one successor.
       
       In other words, a \textit{function} type is replaced by a new anonymous function, and for each of its inputs is added a fresh variable into the context of its body -- which results in possibility of using those new variables inside the body of the anonymous function. Notice that this rule is never used in problems satisfying the closure requirement.
 \item \textit{Atomic rule:} 
 
 If $L = \ul{\alpha}{\Gamma}$ where $\alpha$ is \textit{atomic} type, then for each 
       \mbox{$f : (\tau_1 \ar \dots \ar \tau_m \ar \alpha) \in \Gamma$}, $m \geq 0$
       the unfinished leaf $L$ is replaced by 
       $(~f~\ul{\tau_1}{\Gamma}~\dots~\ul{\tau_m}{\Gamma}~)$.
       Thus this expansion results in many (possibly zero or one) successors.
       
       In other words, an \textit{atomic} type is replaced by a constant symbol (for $m = 0$) or function symbol (for $m>0$) from the local context. Unfinished leafs $\ul{\tau_i}{\Gamma}$ correspond to the argument subtrees yet to be generated -- precisely as in S-expression generation. Notice that for problems satisfying closure requirement only this rule is applicable; therefore standard S-expressions are generated for such a problem.   
\end{enumerate}

\textit{Algorithm 2} summarizes this key phase of generating procedure by pseudocode.

\Pseudokod{Individual generating procedure.}
{\textbf{generate}(Type $\tau$, Context $\Gamma$, Int $n$, Strategy $S$)}{	

	%star je TODO
	%isGoal je TODO
	%heur je TODO
	
	$results \la$ empty set\;	
	
	\While{ $\vert results \vert < n$ }{ 		
		$S.init()$\;
		$open    \la$ empty priority queue \;
		$start  \la \ul{\tau}{\Gamma}$\;   
		$start$.G $\la 0$ \;
		$start$.F $\la 1$ \;  % heur$( $start$ )
		$open$.insert($start$)\;
		\While{$\neg$ $open$.isEmpty() }{
			$term \la$ $open$.popTermWithLowestF()\;
			\eIf{ numUnfinLeafs($term$) = 0 }{
				
				$results$.insert($term$)\;
							
				\If{ $\vert results \vert = n$ }{
					\Return $results$ \;
				}
			}{
				$nexts \la $\textbf{expand}($term$)\;
				$depth \la term$.depthOfExpandedLeaf()\; 
				$nexts' \la S.$\textbf{filter}($nexts$, $depth$)\;			
				\For{$next \in nexts'$ }{
					$heur     \la $numUnfinLeafs($next$)\;
					$next$.G $\la term.$G$ + 1$ \;
					$next$.F $\la next.$G$ + heur$  \;
					$open$.insert($next$)\;			
				}
			}
		}
	}
	
	\Return results
}

\Pseudokod{Expansion (successor) procedure.}
{\textbf{expand}(UnfinishedTerm $term$)}{
	$nexts \la$ empty set\;	
	$\ul{\sigma}{\Gamma} \la $ \textit{DFS-first} unfinished leaf of $term$ \;
	\Switch{$\sigma$}{
	\Case{$\rho_1 \ar \dots \ar \rho_n \ar \alpha: n \geq 1, \alpha$ atomic}{
		$t \la \lamb{x_1 \dots x_n}{\ul{\alpha}{\Gamma,x_1 : \rho_1\dots x_n :\rho_n}}$\;
		$next \la $ replace $\ul{\sigma}{\Gamma}$ in $term$ with $t$\;  		
		$nexts$.insert($next$)
	}\Case{$\alpha$: $\alpha $ atomic}{
		\For{$f : \tau_1 \ar \dots \ar \tau_m \ar \alpha \in \Gamma$, $m \geq 0$  
		}{
			$t \la (~f~\ul{\tau_1}{\Gamma}~\dots~\ul{\tau_m}{\Gamma}~)$\; 
			$next \la $ replace $\ul{\sigma}{\Gamma}$ in $term$ with $t$\;  		
			$nexts$.insert($next$)
		}
	}
	\Return $nexts$
}
}

\Pseudokod{Geometric strategy.}
{Geometric.\textbf{filter}(UnfinTerms $nexts$, Int $depth$)}{
	$nexts' \la$ empty set\;	
	\For{$next \in nexts$}{
		\textbf{with probability} $q^{depth}$ \textbf{do} $nexts'$.insert($next$) 	
	}
	\Return $nexts'$
}


Now that we have all possible successors of $M$, we are about to apply
the \textit{search strategy} $S$. A search strategy is a procedure
which takes as input a set of unfinished terms and returns a subset
of the input set. Therefore, search strategy acts as a filter reducing 
the search space. 

If the queue becomes empty before the desired number $n$ of terms
is generated, then the initial unfinished term $\ul{\tau}{\Gamma}$ 
is inserted to the queue, search strategy $S$
again initializes its internal state and the process continues.
The whole generating procedure is summarized by \textit{Algorithm 1}.

\Lets now discuss three such search strategies.


%\subsubsection{Systematic strategy}
\textit{Systematic strategy}:~~ 
If we use trivial strategy that returns all the inputs, 
then the algorithm systematically generates 
first $n$ smallest lambda terms in their
\textit{long normal form}.


%\subsubsection{Ramped half-and-half strategy}
\textit{Ramped half-and-half strategy}:~~
This is generalization of the standard ramped half-and-half method described 
in \cite{koza92}. If applied to context satisfying closure requirement
(all constants/variables are of the same type, all functions are operations
on this type), it will behave in the same way as the standard method.
The internal state of this strategy consists of two variables.
It is the only one strategy described here that uses an internal state.

\begin{enumerate}
 \item \textit{isFull} - A boolean value, determining whether \textit{full}
                     or \textit{grow} method will be performed.
 \item \textit{d} - An integer value from $\setDots{2}{D_{init}}$, where 
                $D_{init}$ is predefined maximal depth (e.g. 6).                    
\end{enumerate}

This strategy returns precisely one randomly
(uniformly) selected  element from 
the \textit{selection subset} of input set
(or zero elements if the input set is empty). 
The \textit{selection subset} 
to select from is determined by $depth, d$ and $isFull$.
The $depth$ parameter is the depth (in the term tree) 
of the unfinished leaf that was expanded.
Those elements of input set whose newly added subtree contains one ore more 
unfinished leafs are regarded as \textit{non-terminals}, whereas 
those whose newly added subtree contains no unfinished leaf are regarded as 
\textit{terminals}.
If $depth = 0$, then the subset to select from is  
set of all \textit{non-terminals} of the input set.
If $depth = d$, then the subset to select from is
set of all \textit{terminals} of the input set.
In other cases of $depth$ it depends on value of $isFull$.
If $isFull = true$, then the subset to select from is 
set of all \textit{non-terminals} of the input set.
If $isFull = false$, then the subset to select from is 
the whole input set.


%\subsubsection{Geometric strategy}
\textit{Geometric strategy}:~~
We can see those two previous strategies as two extremes on the spectrum of 
possible strategies. 
\textit{Systematic strategy} filters no successor state thus performing
exhaustive search resulting in discovery of $n$ smallest terms in one run.
On the other hand, \textit{ramped half-and-half strategy} filters 
all but one successor states resulting in degradation of 
the priority queue into "fancy variable".
\textit{Geometric strategy} is simple yet fairly effective term generating 
strategy somewhere in the middle of this spectrum.
It is parameterized by parameter $q \in (0,1)$, its default well-performing 
value is $q = 0.75$.
For each element of the input set 
it is probabilistically decided whether
it will be returned or omitted. A probability $p$ of returning is
same for all elements, but depends on the $depth$, 
which is defined in the same way as in previous strategy. 
It is computed as follows.
$$ p = q^{depth} $$

This formula is motivated by idea that it is important to
explore all possible root symbols, but as the $depth$ 
increases it becomes less "dangerous" to omit 
an exploration branch. 
We can see this by considering that this strategy results in
somehow forgetful A* search.
With each omission we make the search space smaller. But with
increasing depth these omissions have smaller impact on the search space,
i.e., they cut out lesser portion of the search space.
Another slightly esoteric argument supporting this formula is that "root 
parts" of a program usually stand for more crucial parts
with radical impact on global behavior of a program, 
whereas "leaf parts" of a program usually
stand for less important local parts (e.g. constants).  
This strategy also plays nicely with the idea that 
"too big trees should be killed". 
\textit{Algorithm 3} summarizes the filtration procedure performed by the geometric strategy. 

Furthermore, our system utilizes generalization of the standard 
tree-swapping crossover operator. Since it is beyond the scope of this 
paper we mention it only briefly. Two main concerns with swapping typed 
subtrees are types and free variables. Well-typed offspring is obtained 
by swapping only subtrees of the same type. Only subtrees with 
corresponding counterpart in the second parent are randomly chosen from.
More interesting problem lies in free variables, which may cause trouble
if swapped somewhere where it is suddenly not bounded. In order to circumvent this
difficulty we utilize technique called \textit{abstraction elimination}\cite{jones87}
that transforms an arbitrary \lterm into \lterm that contains no lambda abstractions
and no bound variables. After the initial population is generated,  it is transformed
by abstraction elimination. Another possible transformation taking place
after initialization is $\eta$-normalization shortening 
rather long long normal form into shorter $\beta\eta$-normal form.  
Another performance enhancing transformation is option of using "applicative" tree representation (coming directly from inductive definition of \lterms) instead of more traditional S-expression representation. Favorable properties of applicative tree representation are also reported in \cite{yu1998polygp}. 

A remarkable benefit of parameterizing the generating method 
by a search strategy taking the form of a simple filtration function
is that such a function can be expressed by functional language in a very 
economical way. Take for instance a search strategy that behaves same
as the \textit{geometric} except that when it comes to 
situation where all the elements are filtered out it
acts as the \textit{ramped half-and-half}. 
Such \textit{strategy composition}
is easily describable as a higher order function. Thus comes 
to mind the possibility of using our system to come up with new
search strategies on its own.










\section{Experiments}
\label{experiments}

We made three experiments comparing the performance of standard 
\textit{ramped half-and-half strategy} with our
\textit{geometric strategy} (with default parameter value $q=0.75$). 

Despite the fact that the geometric strategy was designed for typed GP over lambda trees, it works well also for standard GP problems satisfying the closure requirement. Furthermore, for such problems our approach generates the standard S-expressions only. Another reason for including standard GP benchmarks in our experiments is the fact that the results are seriously affected by the choice of a crossover 
operator. Design of a good crossover for typed GP remains an open problem. Our crossover design for typed GP is quite technical and beyond the scope of this paper, but for problems satisfying the closure requirement it behaves exactly the same as the standard GP crossover. 

Three well known benchmark problems
(Simple symbolic regression, Artificial ant and
Even parity problem) were chosen for our experiments.
The first two satisfy the closure requirement, 
whereas the third one does not.
In order to ensure that the experiments are replicable we chose to use the standard GP system described in \cite{koza92}, with all the parameters set to their default values (which are summarized in table~I), with the following exceptions:

\begin{enumerate}
  \item In the second and third experiment the preservation of the best individual into the next generation is performed.
  \item In the third experiment we use our crossover operation briefly mentioned above together with the appropriate tree representation.
\end{enumerate}

For problems satisfying closure requirement our generating method generates S-expressions. Therefore it can be directly plugged into the standard GP system.
Each experiment consisted of 50 independent runs 
of a GP algorithm. Each run had a limit of 51 generations, and the population size
was 500 individuals.
In the experiments we analyze the fitness of the best individual,
the average size of an individual,
the ability of the system to produce a correct solution 
and the computational cost estimates throughout generations. 
For the last two metrics we use the popular measurement  
methods within the GP field --- the \textit{performance curves}
described in \cite{koza92} --- $P(M,i)$ (cumulative probability of success) 
and $I(M,i,z)$ (the total number of individuals that must be processed 
to yield a correct solution with probability $z =99\%$).
The difference of those two generating methods 
is statistically analyzed by the Welch t-test
by comparing the fitness values of the best individuals of the run. 
The graphs showing mean values of the fitness of the best individual and
the average size of individuals throughout generations
contain error bars representing the standard error of the mean (SEM).

The experiments were performed under identical conditions on a fairly standard
desktop computer with 4 core 3.3 GHz processor and 4 GB RAM. The running times noted for each experiment should be considered only a rough estimate of the time complexity of particular methods.   

\begin{table}[!t]
\caption{Standard GP parameters.}
\centering
\begin{tabular}{|l|c|}
\hline
~&~\\
Population size             & 500\\
Number of generations       & 51\\
Probability of crossover    & 90\%\\
Probability of reproduction & 10\%\\
Probability of mutation     & 0\%\\
Max depth (initial)         & 6\\
Max depth (crossover)       & 17\\
Representation              & S-expressions\\
Crossover                   & Standard tree swapping (90-10)\\
Selection                   & Fitness-proportionate\\
~&~\\
\hline
Generating method           & Ramped half-and-half / geometric s.\\
\hline
\end{tabular}
\end{table}

\subsection{Simple Symbolic Regression}

\begin{figure}[!ht]
  \centering
  \caption{Graphs for Simple symbolic regression.}
  \includegraphics[scale=0.115]{imgs/SSR.eps}
\end{figure}


\textit{Simple Symbolic Regression} is a problem described
in \cite{koza92}. The objective of this problem is to 
find a function $f(x)$ that fits a sample
of twenty given points. The target function is 
a function defined as $f_{t}(x) = x^4 + x^3 + x^2 + x$.  
The desired type of generated programs $\tau$ and 
the building blocks context $\Gamma$ are the following.
\begin{align*}
\tau = \Real \ar &\Real\\
\Gamma = \{
  (+)  &: \Real \ar \Real \ar \Real    ,~ 
  (-)   : \Real \ar \Real \ar \Real    ,~\\
  (*)  &: \Real \ar \Real \ar \Real    ,~ 
  rdiv  : \Real \ar \Real \ar \Real    ,~\\
  sin  &: \Real \ar \Real              ,~ 
  cos   : \Real \ar \Real              ,~\\
  exp  &: \Real \ar \Real              ,~ 
  rlog  : \Real \ar \Real              \}
\end{align*}
where

\noindent
\begin{minipage}{.9\linewidth}
\begin{align*}
rdiv(p,q) &= \begin{cases} 1 &\mbox{if } q = 0 \\
p/q & \mbox{otherwise } \end{cases}  
\end{align*}
\end{minipage}%

\begin{minipage}{.9\linewidth}
\begin{align*}
rlog(x) &= \begin{cases} 0 &\mbox{if } x = 0 \\
log(\vert x\vert) & \mbox{otherwise}. \end{cases}
\end{align*}
\end{minipage}

The fitness function is computed as follows.

$$ fitness(f) =  \frac{1}{1+ \sum\limits_{i=1}^{20}{ \vert f(x_i)-y_i }\vert }  $$
where $(x_i,y_i)$ are 20 data samples from $[-1,1]$, such that $y_i = f_t(x_i)$.
An individual $f$ such that $\vert f(x_i)-y_i \vert < 0.01 $ for all data samples is 
considered as a correct individual.





\begin{table}[!t]
\caption{Statistical analysis - Simple symbolic regression.}
\centering
\begin{tabular}{|l|cc|}
\hline
& Ramped half-and-half & Geometric \\
\hline
Mean & 0.7999030182 & 0.8174067512 \\
SD	 & 0.1521369287	& 0.1826109800 \\
SEM	 & 0.0215154108	& 0.0258250925 \\
N	 & 50 & 50  \\
\hline
t-value & 0.5207 & $\alpha = 0.05$\\
p-value & 0.6038 & \textbf{Not statistically significant.}\\
\hline
\end{tabular}
\end{table}

Figure~1 shows the results of this experiment. 
Table~II summarizes statistical analysis
of the fitness values of the best individuals of the run 
(\textit{p-value} $ = 0.6038$).  
By conventional criteria, this difference is considered to be not statistically significant.
Standard \textit{ramped half-and-half strategy} scored 17/50 (34\%) success rate. 
The minimal $I(M,i,z)$ value was in the generation 23 with 192,000 individuals to be processed.
The average individual size for generation 50 was 68.8.
The experiment took 46 minutes.
Our \textit{geometric strategy} scored 21/50 (42\%) success rate. 
The minimal $I(M,i,z)$ value was in generation 29 with 150,000 individuals to be processed.
The average individual size for generation 50 was 44.1.
The experiment took 26 minutes.
Thus, for the \textit{Simple symbolic regression}
our geometric strategy is slightly more successful than 
the ramped half-and-half strategy in these observed metrics.



\subsection{Artificial Ant}
\textit{Artificial Ant} is another problem described
in \cite{koza92}. The objective of this problem is to 
find a control program for an artificial ant so
that it can find all food items located on the "Santa Fe" trail.
The Santa Fe trail lies on a toroidal square grid.
The ant is in the upper left corner, facing right.
The ant is able to move forward, turn left, and sense if a food 
piece is ahead of him.
\begin{align*}
\tau~ = An&tAct\\
\Gamma = \{~~
  l    &: AntAct                              ,
  r    : AntAct                               ,
  m    : AntAct                               ,\\
  ifa  &: AntAct \ar AntAct \ar AntAct  ,\\
  p2   &: AntAct \ar AntAct \ar AntAct  ,\\
  p3   &: AntAct \ar AntAct \ar AntAct \ar AntAct  \}
\end{align*}

The actions $l$ and $r$ turn the ant left and right, respectively. 
The action $m$ moves the ant forward.
The action $ifa~x~y$ \mbox{(\textit{if-food-ahead})} 
performs the action $x$ if a food piece is ahead of the ant,
otherwise it performs the action $y$.
The actions $p2$ and $p3$ perform two and three consecutive actions, respectively.
The actions $l, r$ and $m$ each take one time step to execute.
An ant action is performed over and over again until it reaches the predefined
maximal number of steps. 
The fitness value is equal to number of eaten food pieces.
An individual such that eats all 89 pieces of food is 
considered a correct solution.
This limit is set to be 600 time steps\footnote{
In \cite{koza92} this limit is said to be 400 time steps.
But there is also one solution mentioned as correct but needing 545 time steps. (for 400 time steps it eats only 79 pieces of food). 
%But there is also mentioned following solution, which is described as correct solution: \texttt{(ifa m (p3 l (p2 (ifa m r) (p2 r (p2 l r)))(p2 (ifa m l) m)))}.
%This program needs 545 time steps; if it is given only 400 time steps, then it eats only 79 pieces of food. 
Thus we use 600 time steps. 
}.

\begin{figure}[!ht]
  \centering
  \caption{Graphs for Artificial ant problem.}
  \includegraphics[scale=0.112]{imgs/ANT.eps}
\end{figure}

\begin{table}[!t]
\caption{Statistical analysis - Artificial ant problem.}
\centering
\begin{tabular}{|l|cc|}
\hline
& Ramped half-and-half & Geometric \\
\hline
Mean & 66.20 & 79.78 \\
SD	 & 12.33 & 8.77  \\
SEM	 & 1.74	 & 1.24  \\
N	 & 50    & 50    \\
\hline
t-value &  6.3479           & $\alpha = 0.05$\\
p-value &  \textless 0.0001 &  \textbf{Extremely stat. significant.}\\
\hline
\end{tabular}
\end{table}


Figure~2 shows results of this experiment. 
Table~III summarizes statistical analysis
of the fitness values of the best individuals of the run 
(\textit{p-value} $ < 0.0001$).  
According to this analysis our strategy performed better;
by conventional criteria, this difference is considered to be extremely statistically significant.
The standard \textit{ramped half-and-half strategy} scored 7/50 (14\%) success rate. 
The minimal $I(M,i,z)$ value was in the generation 28 with 449,500 individuals to be processed.
The average individual size for generation 50 was 279.5.
The experiment took 265 minutes.
Our \textit{geometric strategy} scored 19/50 (38\%) success rate. 
The minimal $I(M,i,z)$ value was in generation 10 with 115,500 individuals to be processed.
The average individual size for generation 50 was 94.1.
The experiment took 107 minutes.
This is a big improvement in all watched factors.

\subsection{Even Parity Problem}

The previous two problems were instances of standard GP, i.e. their building 
symbols obeyed the closure requirement. This third experiment will 
break the closure requirement, thus it is an ideal candidate for testing typed GP techniques. 
The even-parity function is a boolean function taking as inputs $N$
boolean values and returning \textit{True} if an even number of inputs 
are \textit{True}. For odd number it returns \textit{False}.
This problem has been used by many researchers
as a benchmark for GP. We compare our results with 
that obtained by Yu in \cite{yu01},
where an approach to evolve recursive and modular programs
by use of higher-order functions and $\lambda$-abstractions is presented.
We use very similar set of \textit{building symbols} as in \cite{yu01}. 
\begin{align*}
\tau = [Boo&l] \ar Bool\\
\Gamma = \{
  and   &: Bool \ar Bool \ar Bool                              ,\\
  or    &: Bool \ar Bool \ar Bool                              ,\\
  nand  &: Bool \ar Bool \ar Bool                              ,\\
  nor   &: Bool \ar Bool \ar Bool                              ,\\
  foldr &: (Bool \ar Bool \ar Bool) \\
        &~~~\ar Bool \ar [Bool] \ar Bool ,\\
  head' &: [Bool] \ar Bool                                   ,\\
  tail' &: [Bool] \ar [Bool]                              \}
\end{align*}

The type $[Bool]$ stands for \textit{list of $Bool$s} and for purpose of
this problem is considered atomic.
Unlike in \cite{yu01}, we use specific instance of polymorphic 
function \texttt{foldr}. 
Modifications of functions \texttt{head} 
(returning the first element of the list) 
and \texttt{tail} (returning the list without the first element) are used; 
making them total by returning default value \textit{False}
and \texttt{[]}, respectively.
We use the same fitness function as in \cite{yu01}. 
The fitness function examines the individual by giving
it all possible boolean lists of length 2 and 3.

\begin{figure}[!ht]
  \centering
  \caption{Graphs for Even parity problem.}
  \includegraphics[scale=0.111]{imgs/EP.eps}
\end{figure}

\begin{table}[!t]
\caption{Statistical analysis - Even parity problem.}
\centering
\begin{tabular}{|l|cc|}
\hline
& Ramped half-and-half & Geometric \\
\hline
Mean & 0.895000	& 0.930000 \\
SD	 & 0.075170	& 0.078490 \\
SEM	 & 0.010631	& 0.011100 \\
N	 & 50    & 50    \\
\hline
t-value &  2.2772 & $\alpha = 0.05$\\
p-value &  0.0250 &  \textbf{Statistically significant.}\\
\hline
\end{tabular}
\end{table}

Figure~3 shows results of this experiment. 
Table~IV summarizes statistical analysis
of the fitness values of the best individuals of the run 
(\textit{p-value} $ = 0.0250$).  
According to this analysis our strategy performed better;
by conventional criteria, this difference is considered to be 
statistically significant.

The standard \textit{ramped half-and-half strategy} scored 9/50 (18\%) success rate. 
The minimal $I(M,i,z)$ value was in generation 17 with 333,000 individuals to be processed.
The average individual size for generation 50 was 47.7.
The experiment took 28 minutes.
Our \textit{geometric strategy} scored 32/50 (64\%) success rate. 
The minimal $I(M,i,z)$ value was in generation 0 with 28,000 individuals to be processed.
The average individual size for generation 50 was 74.3.
The experiment took 33 minutes.

Once again, this represents a big improvement over the standard GP method. 

One may get the impression that geometric strategy 
suffers from bloat here, but as is stated in \cite{fg}: 
\textit{"We should not equate growth with bloat
and we should define bloat as program growth without 
(significant) return in terms of fitness."}
Considering that it performs significantly better and
that term size around 75 is similar as for the previous two problems, 
it seems to us that the ramped half-and-half strategy may have difficulties with 
constructing more complex terms, and therefore it is "staying small".

Another itnteresting observation is that 4 times out of 50 (8\% of all runs) 
the 100\% correct solution was present in the generation 0. This is good
result for uninformed search. However, our results are less successful 
than those presented in \cite{yu01} (with slightly different set of 
building symbols); they scored 40/50 (80\%) success rate and $I(M,i,z)$ of 
17,500 in generation 4. But by an observation of the typical solution which is often
some modification of \texttt{foldr xor True inputList} one sees that the important 
task for GP here is to create the \texttt{xor} function. This is the advantage for the 
more specialized term representation used in \cite{yu01} 
(restricting the use of outer variables). 
The difference in crossover operators may also be involved in the difference, 
but such analysis is beyond the scope of this paper. 
Finally, our result at least outperforms other results mentioned in \cite{yu01}: \textit{Generic genetic programming} 
scored 17/60 (28\%); min $I(M,i,z) = 220,000$. \textit{GP with ADFs} 
scored 10/29 (34\%); min $I(M,i,z) = 1,440,000$.

\section{Conclusions}
\label{conclusions}

In this work, we have proposed a generalization of genetic programming 
for simply typed lambda calculus. The main focus of this paper is on the individual generation algorithms. 
The main idea is to explore the spectrum of available approaches bounded on one end by the traditional
ramped half-and-half strategy, while the second bound represents an exhaustive systematic search. 
Thus, three population initialization methods have been designed, 
depending on different search strategies. 
The first strategy corresponds to the above mentioned traditional genetic programming initialization,  
the second one corresponds to exhaustive search, and the third one 
represents a novel geometric strategy.
%\red{ [větu dvě o experimentech]}
Experiments on three well 
known benchmark problems show
that the geometric strategy outperforms
the standard ramped half-and-half 
generating method in success rate, best fitness value,
time consumption and average individual size.
The relevance of these algorithms does not effect only initialization, but it can be used during mutation
operator in a straightforward way. 
%Other performance enhancements based on theory of lambda calculus are 
%proposed and supported by experiments, including abstraction 
%elimination that enables us to utilize
%a simple tree-swapping crossover.


Our future research will focus on exploring other possible search strategies positioned in the middle ground 
identified in this paper. Since the search strategy can be easily described by a rather simple filtration algorithm, it might be
interesting to allow the typed GP system to evolve the search strategy it 
utilizes in a kind of meta-evolution way. 

\section*{Acknowledgements}
Tom\'{a}\v{s} K\v{r}en has been partially supported by the project GA \v{C}R P202/10/1333 and by the SVV project number 260~104. Roman Neruda has been partially supported by the The Ministry of Education of the Czech Republic project COST LD 13002.


%\nocite{*}

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,evogp}



% that's all folks
\end{document}
